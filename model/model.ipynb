{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to initially play around with keras and the kobe data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        0.0\n",
       "2        1.0\n",
       "3        0.0\n",
       "4        1.0\n",
       "        ... \n",
       "30692    0.0\n",
       "30693    NaN\n",
       "30694    1.0\n",
       "30695    0.0\n",
       "30696    0.0\n",
       "Name: shot_made_flag, Length: 30697, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['shot_made_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to split with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24557\n",
      "24557\n",
      "6140\n",
      "30697\n",
      "30697\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split with pandas, WIP\n",
    "split_on = int(len(data) * .8)\n",
    "print(split_on)\n",
    "\n",
    "train = data.iloc[:split_on, :]\n",
    "validation = data.iloc[split_on:, :]\n",
    "print(len(train))\n",
    "print(len(validation))\n",
    "print(len(validation) + len(train))\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action_type            object\n",
       "combined_shot_type     object\n",
       "game_event_id           int64\n",
       "game_id                 int64\n",
       "lat                   float64\n",
       "loc_x                   int64\n",
       "loc_y                   int64\n",
       "lon                   float64\n",
       "minutes_remaining       int64\n",
       "period                  int64\n",
       "playoffs                int64\n",
       "season                 object\n",
       "seconds_remaining       int64\n",
       "shot_distance           int64\n",
       "shot_made_flag        float64\n",
       "shot_type              object\n",
       "shot_zone_area         object\n",
       "shot_zone_basic        object\n",
       "shot_zone_range        object\n",
       "team_id                 int64\n",
       "team_name              object\n",
       "game_date              object\n",
       "matchup                object\n",
       "opponent               object\n",
       "shot_id                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to split with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.csv', 'r') as f:\n",
    "    data = list(csv.reader(f, delimiter=\",\"))\n",
    "data = np.array(data)\n",
    "\n",
    "header = data[0]\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of non_test set: 25697\n",
      "length of test set: 5000\n"
     ]
    }
   ],
   "source": [
    "# Extract the 5000 rows that have a missing label, i.e. the test set\n",
    "\n",
    "def split(arr, cond):\n",
    "    return [arr[cond], arr[~cond]]\n",
    "\n",
    "split_data = split(data, data[:, 14] != '')\n",
    "\n",
    "non_test = split_data[0]\n",
    "test = split_data[1]\n",
    "\n",
    "print('length of non_test set:', len(non_test))\n",
    "print('length of test set:', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: To avoid leakage: method should only train on events that occurred prior to the shot for which you are predicting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid leakage\n",
    "For more info on leakage, see:\n",
    "\n",
    "https://www.kaggle.com/dansbecker/data-leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train set: 6139\n",
      "length of validation set: 24558\n",
      "[['Jump Shot' 'Jump Shot' '10' '20000012' '33.9723' '167' '72'\n",
      "  '-118.1028' '10' '1' '0' '2000-01' '27' '18' '' '2PT Field Goal'\n",
      "  'Right Side(R)' 'Mid-Range' '16-24 ft.' '1610612747'\n",
      "  'Los Angeles Lakers' '2000-10-31' 'LAL @ POR' 'POR' '1']\n",
      " ['Jump Shot' 'Jump Shot' '12' '20000012' '34.0443' '-157' '0'\n",
      "  '-118.4268' '10' '1' '0' '2000-01' '22' '15' '0' '2PT Field Goal'\n",
      "  'Left Side(L)' 'Mid-Range' '8-16 ft.' '1610612747' 'Los Angeles Lakers'\n",
      "  '2000-10-31' 'LAL @ POR' 'POR' '2']\n",
      " ['Jump Shot' 'Jump Shot' '35' '20000012' '33.9093' '-101' '135'\n",
      "  '-118.3708' '7' '1' '0' '2000-01' '45' '16' '1' '2PT Field Goal'\n",
      "  'Left Side Center(LC)' 'Mid-Range' '16-24 ft.' '1610612747'\n",
      "  'Los Angeles Lakers' '2000-10-31' 'LAL @ POR' 'POR' '3']\n",
      " ['Jump Shot' 'Jump Shot' '43' '20000012' '33.8693' '138' '175'\n",
      "  '-118.1318' '6' '1' '0' '2000-01' '52' '22' '0' '2PT Field Goal'\n",
      "  'Right Side Center(RC)' 'Mid-Range' '16-24 ft.' '1610612747'\n",
      "  'Los Angeles Lakers' '2000-10-31' 'LAL @ POR' 'POR' '4']\n",
      " ['Driving Dunk Shot' 'Dunk' '155' '20000012' '34.0443' '0' '0'\n",
      "  '-118.2698' '6' '2' '0' '2000-01' '19' '0' '1' '2PT Field Goal'\n",
      "  'Center(C)' 'Restricted Area' 'Less Than 8 ft.' '1610612747'\n",
      "  'Los Angeles Lakers' '2000-10-31' 'LAL @ POR' 'POR' '5']\n",
      " ['Jump Shot' 'Jump Shot' '244' '20000012' '34.0553' '-145' '-11'\n",
      "  '-118.4148' '9' '3' '0' '2000-01' '32' '14' '0' '2PT Field Goal'\n",
      "  'Left Side(L)' 'Mid-Range' '8-16 ft.' '1610612747' 'Los Angeles Lakers'\n",
      "  '2000-10-31' 'LAL @ POR' 'POR' '6']\n",
      " ['Layup Shot' 'Layup' '251' '20000012' '34.0443' '0' '0' '-118.2698' '8'\n",
      "  '3' '0' '2000-01' '52' '0' '1' '2PT Field Goal' 'Center(C)'\n",
      "  'Restricted Area' 'Less Than 8 ft.' '1610612747' 'Los Angeles Lakers'\n",
      "  '2000-10-31' 'LAL @ POR' 'POR' '7']\n",
      " ['Jump Shot' 'Jump Shot' '254' '20000012' '34.0163' '1' '28' '-118.2688'\n",
      "  '8' '3' '0' '2000-01' '5' '2' '' '2PT Field Goal' 'Center(C)'\n",
      "  'Restricted Area' 'Less Than 8 ft.' '1610612747' 'Los Angeles Lakers'\n",
      "  '2000-10-31' 'LAL @ POR' 'POR' '8']\n",
      " ['Jump Shot' 'Jump Shot' '265' '20000012' '33.9363' '-65' '108'\n",
      "  '-118.3348' '6' '3' '0' '2000-01' '12' '12' '1' '2PT Field Goal'\n",
      "  'Left Side(L)' 'In The Paint (Non-RA)' '8-16 ft.' '1610612747'\n",
      "  'Los Angeles Lakers' '2000-10-31' 'LAL @ POR' 'POR' '9']\n",
      " ['Running Jump Shot' 'Jump Shot' '294' '20000012' '33.9193' '-33' '125'\n",
      "  '-118.3028' '3' '3' '0' '2000-01' '36' '12' '0' '2PT Field Goal'\n",
      "  'Center(C)' 'In The Paint (Non-RA)' '8-16 ft.' '1610612747'\n",
      "  'Los Angeles Lakers' '2000-10-31' 'LAL @ POR' 'POR' '10']]\n"
     ]
    }
   ],
   "source": [
    "# Split the non_test set into a training and a validation set\n",
    "\n",
    "def train_test_split(data, test_percentage: float):\n",
    "    if test_percentage < 0 or test_percentage > 1:\n",
    "        raise ValueError('argument test_percentage must be a float between 0 and 1')\n",
    "\n",
    "    data_len = len(data)\n",
    "    test_size = int(data_len * test_percentage)\n",
    "    \n",
    "    return data[:test_size,:], data[test_size:, :]\n",
    "\n",
    "train, validation = train_test_split(data, 0.2)\n",
    "\n",
    "print('length of train set:', len(train))\n",
    "print('length of validation set:', len(validation))\n",
    "\n",
    "print(train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Encode categoricals to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "le = LabelEncoder()\n",
    "x = le.fit_transform(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set input dimensions equal to the number of columns in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(train[0])\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Needs actual data from the kobe data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data\n",
    "x_train = np.array([[1,2,3], [1,2,2], [1,1,3]])\n",
    "y_train = np.array([1, 0, 1])\n",
    "input_dim = len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "The model works on dummy data, see above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_dim=input_dim))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7820 - accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 465us/step - loss: 0.7465 - accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 447us/step - loss: 0.7239 - accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 439us/step - loss: 0.7066 - accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 467us/step - loss: 0.6930 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x143835510>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = np.array([[1,2,3], [1,2,2], [1,1,3], [2,3,2], [2,1,3]])\n",
    "y_validation = np.array([1, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 180us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_validation, y_validation, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7115203142166138, 0.4000000059604645]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50366366],\n",
       "       [0.48296374],\n",
       "       [0.49760363],\n",
       "       [0.47506434],\n",
       "       [0.46307984]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = model.predict(x_validation, batch_size=128)\n",
    "classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobe",
   "language": "python",
   "name": "kobe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
