{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/misharigot/kobe/blob/master/src/model/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pl5KceKr8HWB"
   },
   "source": [
    "This notebook contains the neural network to predict kobe's shots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQF73eWo8HWF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P32ha3sG8HWH",
    "outputId": "57c6a5d5-0c5d-4301-d86c-be20ad40023d"
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')  # Needed to make the import below work\n",
    "\n",
    "from multiple_train_test_splits import MultipleTrainTestSplits\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as ft\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Combine the minutes and seconds remaining columns into one column.\n",
    "    \"\"\"\n",
    "    df['minutes_remaining'] = df['minutes_remaining'].astype(int)\n",
    "    df['seconds_remaining'] = df['seconds_remaining'].astype(int)\n",
    "\n",
    "    # Combine minutes and seconds remaining into decimal minutes remaining, e.g. 6.5 for 6 mins and 30 secs.\n",
    "    df['time_remaining'] = round(df['minutes_remaining'] + (df['seconds_remaining'] / 60), 2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df: pd.DataFrame, encoder: preprocessing.OneHotEncoder = None) -> pd.DataFrame:\n",
    "    \"\"\"One-hot encode all categorical columns.\n",
    "    Optionally provide an encoder. Use the training set encoder to one-hot encode the test set.\n",
    "    \"\"\"\n",
    "     # Categorize all columns based on their data type\n",
    "    categorical_columns = [\n",
    "        'action_type',\n",
    "        'combined_shot_type',\n",
    "        'game_event_id', # Meaning?\n",
    "        'game_id',\n",
    "        'season',\n",
    "        'shot_type',\n",
    "        'shot_zone_area',\n",
    "        'shot_zone_basic',\n",
    "        'shot_zone_range',\n",
    "        'team_id',\n",
    "        'team_name',\n",
    "        'matchup',\n",
    "        'opponent'\n",
    "    ]\n",
    "\n",
    "    temporal_columns = [\n",
    "        'game_date'\n",
    "    ]\n",
    "\n",
    "    remaining_columns = [\n",
    "        'lat',\n",
    "        'loc_x',\n",
    "        'loc_y',\n",
    "        'lon',\n",
    "        'period',\n",
    "        'shot_distance',\n",
    "        'time_remaining',\n",
    "        'shot_made_flag'  # y label\n",
    "    ]\n",
    "\n",
    "    excluded_columns = [\n",
    "        'shot_id',            # Just an auto-increment id, does not mean anything\n",
    "        'minutes_remaining',  # Not needed, since we use the engineered field 'time_remaining'\n",
    "        'seconds_remaining'   # Not needed, since we use the engineered field 'time_remaining'\n",
    "    ]\n",
    "\n",
    "    # Convert relevant columns to categorical columns\n",
    "    df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "    df_with_only_categoricals = df[categorical_columns]\n",
    "\n",
    "    # One hot encode categorical columns\n",
    "    if encoder is None:\n",
    "        encoder = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "        encoder.fit(df_with_only_categoricals)\n",
    "    one_hot_encoded_df = pd.DataFrame(encoder.transform(df_with_only_categoricals).toarray())\n",
    "    \n",
    "\n",
    "    # Combine the one hot encoded part of the df with the remaining df\n",
    "    non_categorical_df = df[remaining_columns]\n",
    "    resulting_df = pd.concat([one_hot_encoded_df, non_categorical_df], axis=1)\n",
    "    return resulting_df, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Returns the features.\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=['shot_made_flag'])\n",
    "    return X\n",
    "\n",
    "def get_y(data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Returns the target.\n",
    "    \"\"\"\n",
    "    Y = data['shot_made_flag'].copy()\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data: pd.DataFrame, encoder:preprocessing.OneHotEncoder = None) -> np.array:\n",
    "    \"\"\"Preprocess the raw kobe data from Kaggle.\n",
    "    Optionally provide an encoder. Use the training set encoder to one-hot encode the test set.\n",
    "    \"\"\"\n",
    "    df = combine_time(data)\n",
    "    df, encoder = one_hot_encode(df, encoder)\n",
    "    \n",
    "    return df, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(input_dim: int):\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Dense(units=64, activation='relu', input_dim=input_dim))\n",
    "#     model.add(Dense(units=1, activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer='rmsprop',\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sbi8PrU8HXm",
    "outputId": "79b3a233-10c7-4e46-fe67-a71c3d7917b1"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-afc03ebb5449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# We set the number of neighbors to 15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_2d_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "mtts = MultipleTrainTestSplits(csv_path='../../data/data.csv')\n",
    "\n",
    "test_set = mtts.test_set\n",
    "\n",
    "loss_and_metrics = []\n",
    "\n",
    "for train_set, validation_set in mtts.train_validation_split(as_dataframe=True):\n",
    "    # Preprocess the training set\n",
    "    preprocessed_train_set, one_hot_encoder = preprocess(train_set)\n",
    "    # Split the features from the target\n",
    "    x_train = get_x(preprocessed_train_set)\n",
    "    y_train = get_y(preprocessed_train_set)\n",
    "\n",
    "    # Preprocess the validation set (use the one hot encoder that was fit on the training set)\n",
    "    preprocessed_validation_set, _ = preprocess(validation_set, encoder=one_hot_encoder)\n",
    "    # Split the features from the target\n",
    "    x_validation = get_x(preprocessed_validation_set)\n",
    "    y_validation = get_y(preprocessed_validation_set)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(3) # We set the number of neighbors to 15\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_predicted = knn.predict(x_validation)\n",
    "    scores.append(accuracy_score(y_validation, y_predicted))\n",
    "    print('Loop:', 3 ,'accuracy ', accuracy_score(y_validation, y_predicted))\n",
    "    \n",
    "    # try K=1 through K=X and note the testing accuracy\n",
    "#     k_range = range(1, 4)\n",
    "\n",
    "\n",
    "#     for k in k_range:\n",
    "        \n",
    "\n",
    "    #plot_decision_regions(x_train[:500].to_numpy(), y_train.astype(np.integer)[:500].to_numpy(), clf=knn, feature_index = [0,1], res=0.1); # This is a slow classifier, so we reduce the resolution    \n",
    "\n",
    "#     # allow plots to appear within the notebook\n",
    "#     %matplotlib inline\n",
    "\n",
    "#     # plot the relationship between K and testing accuracy\n",
    "#     # plt.plot(x_axis, y_axis)\n",
    "#     plt.plot(k_range, scores)\n",
    "#     plt.xlabel('Value of K for KNN')\n",
    "#     plt.ylabel('Testing Accuracy')\n",
    "\n",
    "    #https://www.ritchieng.com/machine-learning-k-nearest-neighbors-knn/\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     input_dim = x_train.shape[1]  # number of columns (dimensions for the input layer of the model)\n",
    "    \n",
    "#     model = create_model(input_dim=input_dim)\n",
    "#     model.fit(x_train, y_train, epochs=2, batch_size=32)\n",
    "\n",
    "#     loss_and_metrics.append(model.evaluate(x_validation, y_validation, batch_size=128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-744075cf9db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint_average_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_and_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-744075cf9db7>\u001b[0m in \u001b[0;36mprint_average_metrics\u001b[0;34m(loss_and_metrics)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_and_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mavg_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "def print_average_metrics(loss_and_metrics):\n",
    "    # Get average accuracy\n",
    "    accuracies = []\n",
    "    for row in loss_and_metrics:\n",
    "        accuracies.append(row[1])\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "    print('Average accuracy:', round(avg_accuracy, 4))\n",
    "\n",
    "\n",
    "print_average_metrics(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXdEfk8U8HXz",
    "outputId": "93c02ec8-0302-466c-98da-328924921432"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26074135],\n",
       "       [0.2928418 ],\n",
       "       [0.2698071 ],\n",
       "       ...,\n",
       "       [0.29890507],\n",
       "       [0.9255194 ],\n",
       "       [0.4461364 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = model.predict(x_validation, batch_size=128)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
