{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/misharigot/kobe/blob/master/src/model/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pl5KceKr8HWB"
   },
   "source": [
    "This notebook contains the neural network to predict kobe's shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P32ha3sG8HWH",
    "outputId": "57c6a5d5-0c5d-4301-d86c-be20ad40023d"
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')  # Needed to make the import below work\n",
    "\n",
    "from multiple_train_test_splits import MultipleTrainTestSplits\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as ft\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(min(df['game_date'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months_elapsed(game_date: pd.Series):\n",
    "    game_date\n",
    "    \n",
    "get_months_elapsed(df['game_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df: pd.DataFrame, encoder: preprocessing.OneHotEncoder = None) -> pd.DataFrame:\n",
    "    \"\"\"One-hot encode all categorical columns.\n",
    "    Optionally provide an encoder. Use the training set encoder to one-hot encode the test set.\n",
    "    \"\"\"\n",
    "     # Categorize all columns based on their data type\n",
    "    categorical_columns = [\n",
    "        'action_type',\n",
    "        'combined_shot_type',\n",
    "        'game_id',\n",
    "        'season',\n",
    "        'shot_type',\n",
    "        'shot_zone_area',\n",
    "        'shot_zone_basic',\n",
    "        'shot_zone_range',\n",
    "        'team_id',\n",
    "        'team_name',\n",
    "        'matchup',\n",
    "        'opponent'\n",
    "    ]\n",
    "\n",
    "    temporal_columns = [\n",
    "        'months_elapsed',\n",
    "        'day_of_week'\n",
    "    ]\n",
    "\n",
    "    remaining_columns = [\n",
    "        'period',\n",
    "        'shot_distance',\n",
    "        'shot_made_flag',  # y label\n",
    "    ]\n",
    "\n",
    "    excluded_columns = [\n",
    "        'lat',\n",
    "        'lon',\n",
    "        'game_event_id', # Game event ids that are registered by the NBA probably, not relevant\n",
    "        'shot_id',       # Just an auto-increment id, does not mean anything\n",
    "    ]\n",
    "    \n",
    "    excluded_but_feature_engineered_columns = [\n",
    "        'minutes_remaining',\n",
    "        'seconds_remaining',\n",
    "        'loc_x', # pythagoras\n",
    "        'loc_y', # pythagoras\n",
    "        'game_date', # months_elapsed_from_start & day_of_week\n",
    "    ]\n",
    "\n",
    "    # Convert relevant columns to categorical columns\n",
    "    df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "    df_with_only_categoricals = df[categorical_columns]\n",
    "\n",
    "    # One hot encode categorical columns\n",
    "    if encoder is None:\n",
    "        encoder = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "        encoder.fit(df_with_only_categoricals)\n",
    "    one_hot_encoded_df = pd.DataFrame(encoder.transform(df_with_only_categoricals).toarray())\n",
    "    \n",
    "\n",
    "    # Combine the one hot encoded part of the df with the remaining df\n",
    "    non_categorical_df = df[remaining_columns]\n",
    "    resulting_df = pd.concat([one_hot_encoded_df, non_categorical_df], axis=1)\n",
    "    return resulting_df, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Returns the features.\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=['shot_made_flag'])\n",
    "    return X\n",
    "\n",
    "def get_y(data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Returns the target.\n",
    "    \"\"\"\n",
    "    Y = data['shot_made_flag'].copy()\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data: pd.DataFrame, encoder:preprocessing.OneHotEncoder = None) -> np.array:\n",
    "    \"\"\"Preprocess the raw kobe data from Kaggle.\n",
    "    Optionally provide an encoder. Use the training set encoder to one-hot encode the test set.\n",
    "    \"\"\"\n",
    "    df, encoder = one_hot_encode(data, encoder)\n",
    "    \n",
    "    return df, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sbi8PrU8HXm",
    "outputId": "79b3a233-10c7-4e46-fe67-a71c3d7917b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 3 accuracy  0.5680093403385873\n",
      "Loop: 3 accuracy  0.5508853862619186\n",
      "Loop: 3 accuracy  0.535318155283129\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mtts = MultipleTrainTestSplits(csv_path='../../data/data.csv')\n",
    "\n",
    "test_set = mtts.test_set\n",
    "\n",
    "loss_and_metrics = []\n",
    "\n",
    "for train_set, validation_set in mtts.train_validation_split(as_dataframe=True):\n",
    "    # Preprocess the training set\n",
    "    preprocessed_train_set, one_hot_encoder = preprocess(train_set)\n",
    "    # Split the features from the target\n",
    "    x_train = get_x(preprocessed_train_set)\n",
    "    y_train = get_y(preprocessed_train_set)\n",
    "\n",
    "    # Preprocess the validation set (use the one hot encoder that was fit on the training set)\n",
    "    preprocessed_validation_set, _ = preprocess(validation_set, encoder=one_hot_encoder)\n",
    "    # Split the features from the target\n",
    "    x_validation = get_x(preprocessed_validation_set)\n",
    "    y_validation = get_y(preprocessed_validation_set)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(3) # We set the number of neighbors to 15\n",
    "    knn.fit(x_train, y_train.astype(int))\n",
    "    y_predicted = knn.predict(x_validation)\n",
    "    scores.append(accuracy_score(y_validation.astype(int), y_predicted.astype(int)))\n",
    "    print('Loop:', 3 ,'accuracy ', accuracy_score(y_validation.astype(int), y_predicted.astype(int)))\n",
    "\n",
    "    \n",
    "# Results with old pre-processing\n",
    "# Loop: 3 accuracy  0.5660634364662386\n",
    "# Loop: 3 accuracy  0.5598365440747227\n",
    "# Loop: 3 accuracy  0.5471881689044561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_average_metrics(loss_and_metrics):\n",
    "    # Get average accuracy\n",
    "    accuracies = []\n",
    "    for row in loss_and_metrics:\n",
    "        accuracies.append(row[1])\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "    print('Average accuracy:', round(avg_accuracy, 4))\n",
    "\n",
    "\n",
    "print_average_metrics(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXdEfk8U8HXz",
    "outputId": "93c02ec8-0302-466c-98da-328924921432"
   },
   "outputs": [],
   "source": [
    "classes = model.predict(x_validation, batch_size=128)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kobe",
   "language": "python",
   "name": "kobe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
