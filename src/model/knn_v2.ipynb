{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/misharigot/kobe/blob/master/src/model/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pl5KceKr8HWB"
   },
   "source": [
    "This notebook contains the neural network to predict kobe's shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P32ha3sG8HWH",
    "outputId": "57c6a5d5-0c5d-4301-d86c-be20ad40023d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')  # Needed to make the import below work\n",
    "\n",
    "from multiple_train_test_splits import MultipleTrainTestSplits\n",
    "from preprocessor import Preprocessor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_x(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Returns the features.\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=['shot_made_flag'])\n",
    "    return X\n",
    "\n",
    "def get_y(data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Returns the target.\n",
    "    \"\"\"\n",
    "    Y = data['shot_made_flag'].copy()\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sbi8PrU8HXm",
    "outputId": "79b3a233-10c7-4e46-fe67-a71c3d7917b1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1. Accuracy = 0.5571122786534345\n",
      "k = 1. Accuracy = 0.5508853862619186\n",
      "k = 1. Accuracy = 0.5489394823895699\n",
      "Average per k: 0.5523123824349744\n",
      "\n",
      "k = 2. Accuracy = 0.5752091846662775\n",
      "k = 2. Accuracy = 0.5631445806577156\n",
      "k = 2. Accuracy = 0.569955244210936\n",
      "Average per k: 0.569436336511643\n",
      "\n",
      "k = 3. Accuracy = 0.5742362327301032\n",
      "k = 3. Accuracy = 0.5586690017513135\n",
      "k = 3. Accuracy = 0.5504962054874489\n",
      "Average per k: 0.5611338133229552\n",
      "\n",
      "k = 4. Accuracy = 0.5882467406110138\n",
      "k = 4. Accuracy = 0.5755983654407473\n",
      "k = 4. Accuracy = 0.5732632807939287\n",
      "Average per k: 0.5790361289485633\n",
      "\n",
      "k = 5. Accuracy = 0.5767659077641565\n",
      "k = 5. Accuracy = 0.5682039307258221\n",
      "k = 5. Accuracy = 0.5555555555555556\n",
      "Average per k: 0.566841798015178\n",
      "\n",
      "k = 6. Accuracy = 0.5870791982876046\n",
      "k = 6. Accuracy = 0.573068690406694\n",
      "k = 6. Accuracy = 0.5693714730492314\n",
      "Average per k: 0.5765064539145099\n",
      "\n",
      "k = 7. Accuracy = 0.5779334500875657\n",
      "k = 7. Accuracy = 0.5691768826619965\n",
      "k = 7. Accuracy = 0.5610040863981319\n",
      "Average per k: 0.5693714730492313\n",
      "\n",
      "k = 8. Accuracy = 0.5826036193812025\n"
     ]
    }
   ],
   "source": [
    "mtts = MultipleTrainTestSplits(csv_path='../../data/data.csv')\n",
    "pp = Preprocessor('../../data/data.csv')\n",
    "\n",
    "test_set = mtts.test_set\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "ks = range(1, 51)\n",
    "all_averages = []\n",
    "\n",
    "for k in ks:\n",
    "    accuracies[k] = {}\n",
    "    fold = 0\n",
    "    scores = []\n",
    "\n",
    "    for train_set, validation_set in mtts.train_validation_split(as_dataframe=True):\n",
    "        fold += 1\n",
    "        \n",
    "        # Preprocess the training set\n",
    "        preprocessed_train_set = pp.preprocess(train_set)\n",
    "        # Split the features from the target\n",
    "        x_train = get_x(preprocessed_train_set)\n",
    "        y_train = get_y(preprocessed_train_set)\n",
    "\n",
    "        # Preprocess the validation set (use the one hot encoder that was fit on the training set)\n",
    "        preprocessed_validation_set = pp.preprocess(validation_set)\n",
    "        # Split the features from the target\n",
    "        x_validation = get_x(preprocessed_validation_set)\n",
    "        y_validation = get_y(preprocessed_validation_set)\n",
    "\n",
    "        knn = KNeighborsClassifier(k)\n",
    "        knn.fit(x_train, y_train.astype(int))\n",
    "        \n",
    "        y_predicted = knn.predict(x_validation)\n",
    "        accuracy = accuracy_score(y_validation.astype(int), y_predicted.astype(int))\n",
    "        accuracies[k][fold] = accuracy\n",
    "        \n",
    "        scores.append(accuracy_score(y_validation.astype('int'), y_predicted.astype('int')))\n",
    "\n",
    "        print(f'k = {k}. Accuracy = {accuracy}')\n",
    "    \n",
    "    \n",
    "    avg_accuracy = sum(scores) / len(scores)\n",
    "    all_averages.append(avg_accuracy)\n",
    "    print('Average per k:', avg_accuracy)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "# Results with old pre-processing\n",
    "# Loop: 3 accuracy  0.5660634364662386\n",
    "# Loop: 3 accuracy  0.5598365440747227\n",
    "# Loop: 3 accuracy  0.5471881689044561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# plot the relationship between K and testing accuracy\n",
    "# plt.plot(x_axis, y_axis)\n",
    "plt.plot(np.array(ks), np.array(all_averages))\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def print_average_metrics(accuracies):\n",
    "    for k, folds in accuracies.items():\n",
    "        accs = []\n",
    "        for i, acc in folds.items():\n",
    "           \n",
    "            accs.append(acc)\n",
    "        print(sum(accs)/len(folds))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "print_average_metrics(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relationship between K and testing accuracy\n",
    "# plt.plot(x_axis, y_axis)\n",
    "plt.plot(np.array(k_range), np.array(all_averages))\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXdEfk8U8HXz",
    "outputId": "93c02ec8-0302-466c-98da-328924921432",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "classes = model.predict(x_validation, batch_size=128)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kobe",
   "language": "python",
   "name": "kobe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
