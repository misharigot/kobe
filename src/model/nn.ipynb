{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/misharigot/kobe/blob/master/src/model/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pl5KceKr8HWB"
   },
   "source": [
    "This notebook contains the neural network to predict kobe's shots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQF73eWo8HWF"
   },
   "source": [
    "## To Do from Trello\n",
    "- [x] Implementeren van cross validation.\n",
    "- [ ] Connecten van nieuwe cross validation module met de nn model module.\n",
    "- [ ] Bouwen van verschillende netwerken (vorm, aantal nodes etc.)\n",
    "- [ ] Kijken welke loss function we moeten gebruiken, cross entropy vs log loss. Log loss sowieso proberen om te vergelijken met competition entries.\n",
    "- [ ] Implementeren van model export functie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "UNP7SAMudAib",
    "outputId": "a97318f1-98de-49f5-9c31-1cc4db31e160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'kobe'...\n",
      "remote: Enumerating objects: 178, done.\u001b[K\n",
      "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
      "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
      "remote: Total 178 (delta 74), reused 126 (delta 34), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (178/178), 1.36 MiB | 19.90 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n"
     ]
    }
   ],
   "source": [
    "# When using this notebook in Google Colab, clone the repo in the file system in\n",
    "# order to use the python modules from the repo.\n",
    "!git  clone https://github.com/misharigot/kobe.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "P32ha3sG8HWH",
    "outputId": "3754cefe-c89f-4675-8f71-538127099cae"
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')  # Needed to make the import below work\n",
    "\n",
    "# Use the line below in Colab\n",
    "# from kobe.src.multiple_train_test_splits import MultipleTrainTestSplits\n",
    "\n",
    "# Use the line below in a local env\n",
    "from multiple_train_test_splits import MultipleTrainTestSplits\n",
    "from preprocessor import Preprocessor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JS4xXHyQGCCv"
   },
   "outputs": [],
   "source": [
    "def get_x(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Returns the features.\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=['shot_made_flag'])\n",
    "    return X\n",
    "\n",
    "def get_y(data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Returns the target.\n",
    "    \"\"\"\n",
    "    Y = data['shot_made_flag'].copy()\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0Rei6a8GCC1"
   },
   "outputs": [],
   "source": [
    "def create_model_1(input_dim: int):\n",
    "    \"\"\"Simple one hidden layer network.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=32, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_2(input_dim: int):\n",
    "    \"\"\"2 hidden layers network.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=64, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_3(input_dim: int):\n",
    "    \"\"\"1 hidden layer network with a lot of neurons.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=int(input_dim/2), activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_models_dict():\n",
    "    models = {}\n",
    "    models['model_1'] = create_model_1\n",
    "    # models['model_2'] = create_model_2\n",
    "#     models['model_3'] = create_model_3\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "# first_recorded_game = str(dt.datetime.strptime(\n",
    "#             min(pp.raw_data['game_date']), '%Y-%m-%d').strftime('%Y-%m-%d'))\n",
    "# print(first_recorded_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "5sbi8PrU8HXm",
    "outputId": "712223af-c93d-4694-ec10-6de46847d035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: model_1, Fold: 1\n",
      "object\n",
      "Epoch 1/2\n",
      "3180/5141 [=================>............] - ETA: 1s - loss: 4.9074 - accuracy: 0.5009"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-71a1ddf9bd90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#                   validation_data=(x_validation, y_validation),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#                   callbacks=callbacks_list, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         loss_and_metrics[model_name] = {\n",
      "\u001b[0;32m~/vu/machine-learning/kobe/.venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/vu/machine-learning/kobe/.venv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 184\u001b[0;31m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vu/machine-learning/kobe/.venv/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vu/machine-learning/kobe/.venv/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use in Colab\n",
    "# csv_path = 'kobe/data/data.csv'\n",
    "\n",
    "# Use in local env\n",
    "csv_path = '../../data/data.csv'\n",
    "\n",
    "mtts = MultipleTrainTestSplits(csv_path=csv_path)\n",
    "pp = Preprocessor(path_to_raw_data=csv_path)\n",
    "\n",
    "test_set = mtts.test_set\n",
    "\n",
    "loss_and_metrics = {}\n",
    "models = get_models_dict()\n",
    "\n",
    "# Loop over the models\n",
    "for model_name, model_func in models.items():\n",
    "    # checkpoint_path = \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    # Loop over the train/validation splits/folds\n",
    "    n_fold = 0\n",
    "    for train_set, validation_set in mtts.train_validation_split(as_dataframe=True):\n",
    "        n_fold = n_fold + 1\n",
    "        print(f'Training model: {model_name}, Fold: {n_fold}')\n",
    "        checkpoint_path = f\"{model_name}_fold_{n_fold}_weights-improvement\" + \"-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "        # Preprocess the training set\n",
    "        preprocessed_train_set = pp.preprocess(train_set)\n",
    "        # Split the features from the target\n",
    "        x_train = get_x(preprocessed_train_set)\n",
    "        y_train = get_y(preprocessed_train_set)\n",
    "\n",
    "        # Preprocess the validation set\n",
    "        preprocessed_validation_set= pp.preprocess(validation_set)\n",
    "        # Split the features from the target\n",
    "        x_validation = get_x(preprocessed_validation_set)\n",
    "        y_validation = get_y(preprocessed_validation_set)\n",
    "\n",
    "        input_dim = x_train.shape[1]  # number of columns (dimensions for the input layer of the model)\n",
    "        \n",
    "        # model = create_model(input_dim=input_dim)\n",
    "        model = model_func(input_dim)\n",
    "\n",
    "#         # Create model checkpoint to be able to resume at a checkpoint when training crashes.\n",
    "#         checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#         callbacks_list = [checkpoint]\n",
    "\n",
    "        # Fit the model\n",
    "#         model.fit(x_train, y_train, epochs=2, batch_size=10, \n",
    "#                   validation_data=(x_validation, y_validation),\n",
    "#                   callbacks=callbacks_list, verbose=0)\n",
    "        model.fit(x_train, y_train, epochs=2, batch_size=10)\n",
    "    \n",
    "        loss_and_metrics[model_name] = {\n",
    "            n_fold: model.evaluate(x_validation, y_validation, batch_size=128)\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': {3: [0.8469062415884032, 0.542907178401947]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ixfhtIrGCC8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_3_fold_1 [0.8702678171130186, 0.4384121298789978]\n",
      "model_3_fold_2 [0.6855128304135778, 0.6275539994239807]\n",
      "model_3_fold_3 [0.6699073620982893, 0.6191866397857666]\n"
     ]
    }
   ],
   "source": [
    "def print_average_metrics(loss_and_metrics):\n",
    "    # Get average accuracy\n",
    "    \n",
    "    for k, v in loss_and_metrics.items():\n",
    "        \n",
    "#     accuracies = []\n",
    "#     for row in loss_and_metrics:\n",
    "#         accuracies.append(row[1])\n",
    "#     avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#     print('Average accuracy:', round(avg_accuracy, 4))\n",
    "\n",
    "\n",
    "print_average_metrics(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "hUdO5rBiktrw",
    "outputId": "4145fb67-5ea7-4532-ed6a-623578bddf6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 248\n",
      "  0 drwxr-xr-x  7 Misha  staff    224 Mar 28 21:21 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "  0 drwxr-xr-x  9 Misha  staff    288 Mar 28 17:35 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "  0 drwxr-xr-x  6 Misha  staff    192 Mar 26 23:41 \u001b[1m\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m\n",
      " 32 -rw-r--r--  1 Misha  staff  15084 Mar 28 14:22 decision_tree.ipynb\n",
      "144 -rw-r--r--  1 Misha  staff  70555 Mar 26 23:41 knn_classifier.ipynb\n",
      " 24 -rw-r--r--  1 Misha  staff   9549 Mar 28 20:08 knn_v2.ipynb\n",
      " 48 -rw-r--r--  1 Misha  staff  23091 Mar 28 21:21 nn.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXdEfk8U8HXz",
    "outputId": "93c02ec8-0302-466c-98da-328924921432"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26074135],\n",
       "       [0.2928418 ],\n",
       "       [0.2698071 ],\n",
       "       ...,\n",
       "       [0.29890507],\n",
       "       [0.9255194 ],\n",
       "       [0.4461364 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = model.predict(x_validation, batch_size=128)\n",
    "classes"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kobe",
   "language": "python",
   "name": "kobe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
