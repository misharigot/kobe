{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "kobe",
      "language": "python",
      "name": "kobe"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misharigot/kobe/blob/master/src/model/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pl5KceKr8HWB"
      },
      "source": [
        "This notebook contains the neural network to predict kobe's shots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PQF73eWo8HWF"
      },
      "source": [
        "## To Do from Trello\n",
        "- [x] Implementeren van cross validation.\n",
        "- [ ] Connecten van nieuwe cross validation module met de nn model module.\n",
        "- [ ] Bouwen van verschillende netwerken (vorm, aantal nodes etc.)\n",
        "- [ ] Kijken welke loss function we moeten gebruiken, cross entropy vs log loss. Log loss sowieso proberen om te vergelijken met competition entries.\n",
        "- [ ] Implementeren van model export functie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UNP7SAMudAib",
        "outputId": "ac4f28f0-9d85-4484-8e05-07b65bfcfb51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# When using this notebook in Google Colab, clone the repo in the file system in\n",
        "# order to use the python modules from the repo.\n",
        "!git  clone https://github.com/misharigot/kobe.git\n",
        "!ls -lsa"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kobe'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Counting objects: 100% (301/301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (210/210), done.\u001b[K\n",
            "remote: Total 301 (delta 145), reused 216 (delta 77), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (301/301), 2.19 MiB | 2.01 MiB/s, done.\n",
            "Resolving deltas: 100% (145/145), done.\n",
            "total 20\n",
            "4 drwxr-xr-x 1 root root 4096 Mar 29 13:33 .\n",
            "4 drwxr-xr-x 1 root root 4096 Mar 29 13:30 ..\n",
            "4 drwxr-xr-x 1 root root 4096 Mar 25 16:11 .config\n",
            "4 drwxr-xr-x 7 root root 4096 Mar 29 13:33 kobe\n",
            "4 drwxr-xr-x 1 root root 4096 Mar 18 16:23 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E8ig3DuquVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys; sys.path.insert(0, '..')  # Needed to make the import below work\n",
        "\n",
        "# Use the line below in Colab\n",
        "from kobe.src.multiple_train_test_splits import MultipleTrainTestSplits\n",
        "from kobe.src.preprocessor import Preprocessor\n",
        "\n",
        "# Use the line below in a local env\n",
        "# from multiple_train_test_splits import MultipleTrainTestSplits\n",
        "# from preprocessor import Preprocessor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhD46PMLraSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "944b2408-20fd-42a1-8ab3-7c081cc9b577"
      },
      "source": [
        "# Because colab uses a different Keras version than we do.\n",
        "!pip install keras==\"2.3.1\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P32ha3sG8HWH",
        "outputId": "28a42b32-16de-4f2a-802e-82538037bfdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JS4xXHyQGCCv",
        "colab": {}
      },
      "source": [
        "def get_x(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Returns the features.\n",
        "    \"\"\"\n",
        "    X = data.drop(columns=['shot_made_flag'])\n",
        "    return X\n",
        "\n",
        "def get_y(data: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"Returns the target.\n",
        "    \"\"\"\n",
        "    Y = data['shot_made_flag'].copy()\n",
        "    return Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g0Rei6a8GCC1",
        "colab": {}
      },
      "source": [
        "def create_model_1(input_dim: int):\n",
        "    \"\"\"Simple one hidden layer network.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=32, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_2(input_dim: int):\n",
        "    \"\"\"2 hidden layers network.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=64, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_3(input_dim: int):\n",
        "    \"\"\"1 hidden layer network with a lot of neurons.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=int(input_dim/2), activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_4(input_dim: int):\n",
        "    \"\"\"2 hidden layers network with more neurons per layer.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=int(input_dim/2), activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=int(input_dim/4), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_model_5(input_dim: int):\n",
        "    \"\"\"3 hidden layers network.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=128, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_model_6(input_dim: int):\n",
        "    \"\"\"Simple one hidden layer network with double the dim of model 1.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=64, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_model_7(input_dim: int):\n",
        "    \"\"\"Simple one hidden layer network with double the dim of model 1.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=128, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_models_dict():\n",
        "    models = {}\n",
        "    # models['model_1'] = create_model_1\n",
        "    # models['model_2'] = create_model_2\n",
        "    # models['model_3'] = create_model_3\n",
        "    # models['model_4'] = create_model_4\n",
        "    # models['model_5'] = create_model_5\n",
        "    # models['model_6'] = create_model_6\n",
        "    models['model_7'] = create_model_7\n",
        "\n",
        "    return models\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lpR1vsRqcVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use in Colab\n",
        "csv_path = 'kobe/data/data.csv'\n",
        "\n",
        "# Use in local env\n",
        "# csv_path = '../../data/data.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5sbi8PrU8HXm",
        "outputId": "49442aad-6a4e-4e98-cc69-a654133c9cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mtts = MultipleTrainTestSplits(csv_path=csv_path)\n",
        "pp = Preprocessor(path_to_raw_data=csv_path)\n",
        "\n",
        "test_set = mtts.test_set\n",
        "\n",
        "loss_and_metrics = {}\n",
        "models = get_models_dict()\n",
        "\n",
        "# Loop over the models\n",
        "for model_name, model_func in models.items():\n",
        "    # checkpoint_path = \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "    \n",
        "    loss_and_metrics[model_name] = {}\n",
        "    \n",
        "    # Loop over the train/validation splits/folds\n",
        "    n_fold = 0\n",
        "    for train_set, validation_set in mtts.train_validation_split(as_dataframe=True):\n",
        "        n_fold += 1\n",
        "        print(f'Training model: {model_name}, Fold: {n_fold}')\n",
        "        checkpoint_path = f\"{model_name}_fold_{n_fold}_weights-improvement\" + \"-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "\n",
        "        # Preprocess the training set\n",
        "        preprocessed_train_set = pp.preprocess(train_set)\n",
        "        # Split the features from the target\n",
        "        x_train = get_x(preprocessed_train_set)\n",
        "        y_train = get_y(preprocessed_train_set)\n",
        "\n",
        "        # Preprocess the validation set\n",
        "        preprocessed_validation_set= pp.preprocess(validation_set)\n",
        "        # Split the features from the target\n",
        "        x_validation = get_x(preprocessed_validation_set)\n",
        "        y_validation = get_y(preprocessed_validation_set)\n",
        "\n",
        "        input_dim = x_train.shape[1]  # number of columns (dimensions for the input layer of the model)\n",
        "        \n",
        "        # model = create_model(input_dim=input_dim)\n",
        "        model = model_func(input_dim)\n",
        "\n",
        "#         # Create model checkpoint to be able to resume at a checkpoint when training crashes.\n",
        "#         checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#         callbacks_list = [checkpoint]\n",
        "\n",
        "        # Fit the model\n",
        "#         model.fit(x_train, y_train, epochs=2, batch_size=10, \n",
        "#                   validation_data=(x_validation, y_validation),\n",
        "#                   callbacks=callbacks_list, verbose=0)\n",
        "        model.fit(x_train, y_train, epochs=50, batch_size=128)\n",
        "    \n",
        "        loss_and_metrics[model_name][n_fold] = model.evaluate(x_validation, y_validation, batch_size=128)\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model: model_6, Fold: 1\n",
            "Epoch 1/50\n",
            "5141/5141 [==============================] - 2s 321us/step - loss: 0.6738 - accuracy: 0.5940\n",
            "Epoch 2/50\n",
            "5141/5141 [==============================] - 2s 310us/step - loss: 0.6397 - accuracy: 0.6425\n",
            "Epoch 3/50\n",
            "5141/5141 [==============================] - 2s 302us/step - loss: 0.6200 - accuracy: 0.6575\n",
            "Epoch 4/50\n",
            "5141/5141 [==============================] - 2s 306us/step - loss: 0.6139 - accuracy: 0.6719\n",
            "Epoch 5/50\n",
            "5141/5141 [==============================] - 2s 304us/step - loss: 0.6055 - accuracy: 0.6754\n",
            "Epoch 6/50\n",
            "5141/5141 [==============================] - 2s 312us/step - loss: 0.5988 - accuracy: 0.6775\n",
            "Epoch 7/50\n",
            "5141/5141 [==============================] - 2s 310us/step - loss: 0.5952 - accuracy: 0.6845\n",
            "Epoch 8/50\n",
            "5141/5141 [==============================] - 2s 311us/step - loss: 0.5885 - accuracy: 0.6847\n",
            "Epoch 9/50\n",
            "5141/5141 [==============================] - 2s 301us/step - loss: 0.5856 - accuracy: 0.6841\n",
            "Epoch 10/50\n",
            "5141/5141 [==============================] - 2s 304us/step - loss: 0.5819 - accuracy: 0.6929\n",
            "Epoch 11/50\n",
            "5141/5141 [==============================] - 2s 300us/step - loss: 0.5766 - accuracy: 0.6919\n",
            "Epoch 12/50\n",
            "5141/5141 [==============================] - 2s 300us/step - loss: 0.5781 - accuracy: 0.6859\n",
            "Epoch 13/50\n",
            "5141/5141 [==============================] - 2s 301us/step - loss: 0.5736 - accuracy: 0.6977\n",
            "Epoch 14/50\n",
            "5141/5141 [==============================] - 2s 307us/step - loss: 0.5707 - accuracy: 0.7001\n",
            "Epoch 15/50\n",
            "5141/5141 [==============================] - 2s 296us/step - loss: 0.5667 - accuracy: 0.6977\n",
            "Epoch 16/50\n",
            "5141/5141 [==============================] - 2s 301us/step - loss: 0.5676 - accuracy: 0.6971\n",
            "Epoch 17/50\n",
            "5141/5141 [==============================] - 2s 307us/step - loss: 0.5593 - accuracy: 0.7051\n",
            "Epoch 18/50\n",
            "5141/5141 [==============================] - 2s 308us/step - loss: 0.5608 - accuracy: 0.7014\n",
            "Epoch 19/50\n",
            "5141/5141 [==============================] - 2s 306us/step - loss: 0.5569 - accuracy: 0.7036\n",
            "Epoch 20/50\n",
            "5141/5141 [==============================] - 2s 312us/step - loss: 0.5542 - accuracy: 0.7041\n",
            "Epoch 21/50\n",
            "5141/5141 [==============================] - 2s 308us/step - loss: 0.5494 - accuracy: 0.7067\n",
            "Epoch 22/50\n",
            "5141/5141 [==============================] - 2s 302us/step - loss: 0.5449 - accuracy: 0.7166\n",
            "Epoch 23/50\n",
            "5141/5141 [==============================] - 2s 307us/step - loss: 0.5469 - accuracy: 0.7143\n",
            "Epoch 24/50\n",
            "5141/5141 [==============================] - 2s 303us/step - loss: 0.5453 - accuracy: 0.7178\n",
            "Epoch 25/50\n",
            "5141/5141 [==============================] - 2s 302us/step - loss: 0.5421 - accuracy: 0.7174\n",
            "Epoch 26/50\n",
            "5141/5141 [==============================] - 2s 303us/step - loss: 0.5369 - accuracy: 0.7230\n",
            "Epoch 27/50\n",
            "5141/5141 [==============================] - 2s 301us/step - loss: 0.5365 - accuracy: 0.7203\n",
            "Epoch 28/50\n",
            "5141/5141 [==============================] - 2s 299us/step - loss: 0.5347 - accuracy: 0.7244\n",
            "Epoch 29/50\n",
            "5141/5141 [==============================] - 2s 303us/step - loss: 0.5322 - accuracy: 0.7250\n",
            "Epoch 30/50\n",
            "5141/5141 [==============================] - 2s 303us/step - loss: 0.5292 - accuracy: 0.7259\n",
            "Epoch 31/50\n",
            "5141/5141 [==============================] - 2s 296us/step - loss: 0.5273 - accuracy: 0.7263\n",
            "Epoch 32/50\n",
            "5141/5141 [==============================] - 2s 300us/step - loss: 0.5233 - accuracy: 0.7310\n",
            "Epoch 33/50\n",
            "5141/5141 [==============================] - 2s 303us/step - loss: 0.5218 - accuracy: 0.7362\n",
            "Epoch 34/50\n",
            "5141/5141 [==============================] - 2s 299us/step - loss: 0.5211 - accuracy: 0.7345\n",
            "Epoch 35/50\n",
            "5141/5141 [==============================] - 2s 300us/step - loss: 0.5192 - accuracy: 0.7360\n",
            "Epoch 36/50\n",
            "5141/5141 [==============================] - 2s 300us/step - loss: 0.5139 - accuracy: 0.7376\n",
            "Epoch 37/50\n",
            "5141/5141 [==============================] - 2s 308us/step - loss: 0.5132 - accuracy: 0.7444\n",
            "Epoch 38/50\n",
            "5141/5141 [==============================] - 2s 312us/step - loss: 0.5091 - accuracy: 0.7471\n",
            "Epoch 39/50\n",
            "5141/5141 [==============================] - 2s 307us/step - loss: 0.5073 - accuracy: 0.7471\n",
            "Epoch 40/50\n",
            "5141/5141 [==============================] - 2s 304us/step - loss: 0.5078 - accuracy: 0.7456\n",
            "Epoch 41/50\n",
            "5141/5141 [==============================] - 2s 296us/step - loss: 0.5056 - accuracy: 0.7450\n",
            "Epoch 42/50\n",
            "5141/5141 [==============================] - 2s 302us/step - loss: 0.5030 - accuracy: 0.7518\n",
            "Epoch 43/50\n",
            "5141/5141 [==============================] - 2s 302us/step - loss: 0.5043 - accuracy: 0.7495\n",
            "Epoch 44/50\n",
            "5141/5141 [==============================] - 2s 301us/step - loss: 0.4986 - accuracy: 0.7485\n",
            "Epoch 45/50\n",
            "5141/5141 [==============================] - 2s 315us/step - loss: 0.4979 - accuracy: 0.7504\n",
            "Epoch 46/50\n",
            "5141/5141 [==============================] - 2s 295us/step - loss: 0.4951 - accuracy: 0.7571\n",
            "Epoch 47/50\n",
            "5141/5141 [==============================] - 2s 306us/step - loss: 0.4954 - accuracy: 0.7592\n",
            "Epoch 48/50\n",
            "5141/5141 [==============================] - 2s 307us/step - loss: 0.4920 - accuracy: 0.7576\n",
            "Epoch 49/50\n",
            "5141/5141 [==============================] - 2s 298us/step - loss: 0.4881 - accuracy: 0.7623\n",
            "Epoch 50/50\n",
            "5141/5141 [==============================] - 2s 305us/step - loss: 0.4868 - accuracy: 0.7590\n",
            "5139/5139 [==============================] - 1s 142us/step\n",
            "Training model: model_6, Fold: 2\n",
            "Epoch 1/50\n",
            "10280/10280 [==============================] - 5s 450us/step - loss: 0.6586 - accuracy: 0.6194\n",
            "Epoch 2/50\n",
            "10280/10280 [==============================] - 5s 444us/step - loss: 0.6227 - accuracy: 0.6735\n",
            "Epoch 3/50\n",
            "10280/10280 [==============================] - 5s 440us/step - loss: 0.6075 - accuracy: 0.6837\n",
            "Epoch 4/50\n",
            "10280/10280 [==============================] - 5s 439us/step - loss: 0.6012 - accuracy: 0.6863\n",
            "Epoch 5/50\n",
            "10280/10280 [==============================] - 4s 436us/step - loss: 0.5951 - accuracy: 0.6895\n",
            "Epoch 6/50\n",
            "10280/10280 [==============================] - 4s 426us/step - loss: 0.5913 - accuracy: 0.6880\n",
            "Epoch 7/50\n",
            "10280/10280 [==============================] - 4s 429us/step - loss: 0.5880 - accuracy: 0.6915\n",
            "Epoch 8/50\n",
            "10280/10280 [==============================] - 4s 431us/step - loss: 0.5834 - accuracy: 0.6912\n",
            "Epoch 9/50\n",
            "10280/10280 [==============================] - 4s 436us/step - loss: 0.5806 - accuracy: 0.6933\n",
            "Epoch 10/50\n",
            "10280/10280 [==============================] - 4s 435us/step - loss: 0.5746 - accuracy: 0.6983\n",
            "Epoch 11/50\n",
            "10280/10280 [==============================] - 4s 426us/step - loss: 0.5708 - accuracy: 0.6982\n",
            "Epoch 12/50\n",
            "10280/10280 [==============================] - 4s 428us/step - loss: 0.5665 - accuracy: 0.7018\n",
            "Epoch 13/50\n",
            "10280/10280 [==============================] - 4s 410us/step - loss: 0.5659 - accuracy: 0.7010\n",
            "Epoch 14/50\n",
            "10280/10280 [==============================] - 4s 419us/step - loss: 0.5637 - accuracy: 0.7015\n",
            "Epoch 15/50\n",
            "10280/10280 [==============================] - 4s 419us/step - loss: 0.5588 - accuracy: 0.7061\n",
            "Epoch 16/50\n",
            "10280/10280 [==============================] - 4s 415us/step - loss: 0.5564 - accuracy: 0.7081\n",
            "Epoch 17/50\n",
            "10280/10280 [==============================] - 4s 411us/step - loss: 0.5512 - accuracy: 0.7120\n",
            "Epoch 18/50\n",
            "10280/10280 [==============================] - 4s 415us/step - loss: 0.5495 - accuracy: 0.7141\n",
            "Epoch 19/50\n",
            "10280/10280 [==============================] - 4s 415us/step - loss: 0.5470 - accuracy: 0.7128\n",
            "Epoch 20/50\n",
            "10280/10280 [==============================] - 4s 411us/step - loss: 0.5431 - accuracy: 0.7182\n",
            "Epoch 21/50\n",
            "10280/10280 [==============================] - 4s 412us/step - loss: 0.5423 - accuracy: 0.7192\n",
            "Epoch 22/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.5391 - accuracy: 0.7238\n",
            "Epoch 23/50\n",
            "10280/10280 [==============================] - 4s 410us/step - loss: 0.5374 - accuracy: 0.7205\n",
            "Epoch 24/50\n",
            "10280/10280 [==============================] - 4s 413us/step - loss: 0.5327 - accuracy: 0.7267\n",
            "Epoch 25/50\n",
            "10280/10280 [==============================] - 4s 411us/step - loss: 0.5299 - accuracy: 0.7284\n",
            "Epoch 26/50\n",
            "10280/10280 [==============================] - 4s 412us/step - loss: 0.5287 - accuracy: 0.7293\n",
            "Epoch 27/50\n",
            "10280/10280 [==============================] - 4s 416us/step - loss: 0.5249 - accuracy: 0.7298\n",
            "Epoch 28/50\n",
            "10280/10280 [==============================] - 4s 412us/step - loss: 0.5241 - accuracy: 0.7334\n",
            "Epoch 29/50\n",
            "10280/10280 [==============================] - 4s 410us/step - loss: 0.5210 - accuracy: 0.7354\n",
            "Epoch 30/50\n",
            "10280/10280 [==============================] - 4s 407us/step - loss: 0.5191 - accuracy: 0.7384\n",
            "Epoch 31/50\n",
            "10280/10280 [==============================] - 4s 412us/step - loss: 0.5155 - accuracy: 0.7370\n",
            "Epoch 32/50\n",
            "10280/10280 [==============================] - 4s 418us/step - loss: 0.5146 - accuracy: 0.7415\n",
            "Epoch 33/50\n",
            "10280/10280 [==============================] - 4s 416us/step - loss: 0.5137 - accuracy: 0.7450\n",
            "Epoch 34/50\n",
            "10280/10280 [==============================] - 4s 420us/step - loss: 0.5089 - accuracy: 0.7449\n",
            "Epoch 35/50\n",
            "10280/10280 [==============================] - 4s 416us/step - loss: 0.5057 - accuracy: 0.7508\n",
            "Epoch 36/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.5049 - accuracy: 0.7443\n",
            "Epoch 37/50\n",
            "10280/10280 [==============================] - 4s 416us/step - loss: 0.5021 - accuracy: 0.7508\n",
            "Epoch 38/50\n",
            "10280/10280 [==============================] - 4s 412us/step - loss: 0.5008 - accuracy: 0.7514\n",
            "Epoch 39/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.5006 - accuracy: 0.7542\n",
            "Epoch 40/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.4965 - accuracy: 0.7546\n",
            "Epoch 41/50\n",
            "10280/10280 [==============================] - 4s 409us/step - loss: 0.4950 - accuracy: 0.7572\n",
            "Epoch 42/50\n",
            "10280/10280 [==============================] - 4s 411us/step - loss: 0.4917 - accuracy: 0.7558\n",
            "Epoch 43/50\n",
            "10280/10280 [==============================] - 4s 416us/step - loss: 0.4912 - accuracy: 0.7600\n",
            "Epoch 44/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.4905 - accuracy: 0.7623\n",
            "Epoch 45/50\n",
            "10280/10280 [==============================] - 4s 416us/step - loss: 0.4854 - accuracy: 0.7620\n",
            "Epoch 46/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.4844 - accuracy: 0.7648\n",
            "Epoch 47/50\n",
            "10280/10280 [==============================] - 4s 411us/step - loss: 0.4853 - accuracy: 0.7613\n",
            "Epoch 48/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.4805 - accuracy: 0.7668\n",
            "Epoch 49/50\n",
            "10280/10280 [==============================] - 4s 416us/step - loss: 0.4798 - accuracy: 0.7671\n",
            "Epoch 50/50\n",
            "10280/10280 [==============================] - 4s 414us/step - loss: 0.4765 - accuracy: 0.7694\n",
            "5139/5139 [==============================] - 1s 143us/step\n",
            "Training model: model_6, Fold: 3\n",
            "Epoch 1/50\n",
            "15419/15419 [==============================] - 8s 504us/step - loss: 0.6582 - accuracy: 0.6258\n",
            "Epoch 2/50\n",
            "15419/15419 [==============================] - 8s 494us/step - loss: 0.6172 - accuracy: 0.6766\n",
            "Epoch 3/50\n",
            "15419/15419 [==============================] - 8s 491us/step - loss: 0.6083 - accuracy: 0.6816\n",
            "Epoch 4/50\n",
            "15419/15419 [==============================] - 8s 492us/step - loss: 0.6003 - accuracy: 0.6852\n",
            "Epoch 5/50\n",
            "15419/15419 [==============================] - 8s 488us/step - loss: 0.5975 - accuracy: 0.6858\n",
            "Epoch 6/50\n",
            "15419/15419 [==============================] - 8s 492us/step - loss: 0.5928 - accuracy: 0.6873\n",
            "Epoch 7/50\n",
            "15419/15419 [==============================] - 8s 487us/step - loss: 0.5907 - accuracy: 0.6886\n",
            "Epoch 8/50\n",
            "15419/15419 [==============================] - 8s 490us/step - loss: 0.5866 - accuracy: 0.6899\n",
            "Epoch 9/50\n",
            "15419/15419 [==============================] - 7s 486us/step - loss: 0.5829 - accuracy: 0.6921\n",
            "Epoch 10/50\n",
            "15419/15419 [==============================] - 8s 488us/step - loss: 0.5780 - accuracy: 0.6916\n",
            "Epoch 11/50\n",
            "15419/15419 [==============================] - 8s 491us/step - loss: 0.5783 - accuracy: 0.6917\n",
            "Epoch 12/50\n",
            "15419/15419 [==============================] - 8s 491us/step - loss: 0.5739 - accuracy: 0.6964\n",
            "Epoch 13/50\n",
            "15419/15419 [==============================] - 8s 489us/step - loss: 0.5705 - accuracy: 0.6959\n",
            "Epoch 14/50\n",
            "15419/15419 [==============================] - 8s 489us/step - loss: 0.5666 - accuracy: 0.6997\n",
            "Epoch 15/50\n",
            "15419/15419 [==============================] - 8s 488us/step - loss: 0.5632 - accuracy: 0.7009\n",
            "Epoch 16/50\n",
            "15419/15419 [==============================] - 8s 496us/step - loss: 0.5618 - accuracy: 0.7055\n",
            "Epoch 17/50\n",
            "15419/15419 [==============================] - 8s 503us/step - loss: 0.5593 - accuracy: 0.7080\n",
            "Epoch 18/50\n",
            "15419/15419 [==============================] - 8s 496us/step - loss: 0.5559 - accuracy: 0.7085\n",
            "Epoch 19/50\n",
            "15419/15419 [==============================] - 8s 495us/step - loss: 0.5537 - accuracy: 0.7111\n",
            "Epoch 20/50\n",
            "15419/15419 [==============================] - 8s 502us/step - loss: 0.5490 - accuracy: 0.7120\n",
            "Epoch 21/50\n",
            "15419/15419 [==============================] - 8s 496us/step - loss: 0.5471 - accuracy: 0.7157\n",
            "Epoch 22/50\n",
            "15419/15419 [==============================] - 8s 499us/step - loss: 0.5465 - accuracy: 0.7160\n",
            "Epoch 23/50\n",
            "15419/15419 [==============================] - 8s 501us/step - loss: 0.5435 - accuracy: 0.7207\n",
            "Epoch 24/50\n",
            "15419/15419 [==============================] - 8s 502us/step - loss: 0.5399 - accuracy: 0.7211\n",
            "Epoch 25/50\n",
            "15419/15419 [==============================] - 8s 498us/step - loss: 0.5413 - accuracy: 0.7204\n",
            "Epoch 26/50\n",
            "15419/15419 [==============================] - 8s 497us/step - loss: 0.5345 - accuracy: 0.7266\n",
            "Epoch 27/50\n",
            "15419/15419 [==============================] - 8s 498us/step - loss: 0.5334 - accuracy: 0.7259\n",
            "Epoch 28/50\n",
            "15419/15419 [==============================] - 8s 501us/step - loss: 0.5336 - accuracy: 0.7254\n",
            "Epoch 29/50\n",
            "15419/15419 [==============================] - 8s 500us/step - loss: 0.5312 - accuracy: 0.7268\n",
            "Epoch 30/50\n",
            "15419/15419 [==============================] - 8s 497us/step - loss: 0.5295 - accuracy: 0.7318\n",
            "Epoch 31/50\n",
            "15419/15419 [==============================] - 8s 495us/step - loss: 0.5252 - accuracy: 0.7325\n",
            "Epoch 32/50\n",
            "15419/15419 [==============================] - 8s 501us/step - loss: 0.5219 - accuracy: 0.7347\n",
            "Epoch 33/50\n",
            "15419/15419 [==============================] - 8s 504us/step - loss: 0.5227 - accuracy: 0.7359\n",
            "Epoch 34/50\n",
            "15419/15419 [==============================] - 8s 503us/step - loss: 0.5219 - accuracy: 0.7340\n",
            "Epoch 35/50\n",
            "15419/15419 [==============================] - 8s 498us/step - loss: 0.5181 - accuracy: 0.7376\n",
            "Epoch 36/50\n",
            "15419/15419 [==============================] - 8s 493us/step - loss: 0.5172 - accuracy: 0.7380\n",
            "Epoch 37/50\n",
            "15419/15419 [==============================] - 8s 496us/step - loss: 0.5142 - accuracy: 0.7424\n",
            "Epoch 38/50\n",
            "15419/15419 [==============================] - 8s 499us/step - loss: 0.5097 - accuracy: 0.7440\n",
            "Epoch 39/50\n",
            "15419/15419 [==============================] - 8s 502us/step - loss: 0.5127 - accuracy: 0.7392\n",
            "Epoch 40/50\n",
            "15419/15419 [==============================] - 8s 499us/step - loss: 0.5080 - accuracy: 0.7467\n",
            "Epoch 41/50\n",
            "15419/15419 [==============================] - 8s 502us/step - loss: 0.5070 - accuracy: 0.7458\n",
            "Epoch 42/50\n",
            "15419/15419 [==============================] - 8s 498us/step - loss: 0.5052 - accuracy: 0.7477\n",
            "Epoch 43/50\n",
            "15419/15419 [==============================] - 8s 499us/step - loss: 0.5048 - accuracy: 0.7476\n",
            "Epoch 44/50\n",
            "15419/15419 [==============================] - 8s 498us/step - loss: 0.5016 - accuracy: 0.7491\n",
            "Epoch 45/50\n",
            "15419/15419 [==============================] - 8s 496us/step - loss: 0.5015 - accuracy: 0.7522\n",
            "Epoch 46/50\n",
            "15419/15419 [==============================] - 8s 503us/step - loss: 0.4961 - accuracy: 0.7547\n",
            "Epoch 47/50\n",
            "15419/15419 [==============================] - 8s 503us/step - loss: 0.4976 - accuracy: 0.7546\n",
            "Epoch 48/50\n",
            "15419/15419 [==============================] - 8s 501us/step - loss: 0.4943 - accuracy: 0.7556\n",
            "Epoch 49/50\n",
            "15419/15419 [==============================] - 8s 500us/step - loss: 0.4908 - accuracy: 0.7598\n",
            "Epoch 50/50\n",
            "15419/15419 [==============================] - 8s 507us/step - loss: 0.4908 - accuracy: 0.7580\n",
            "5139/5139 [==============================] - 1s 136us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "196g9iCbqcVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cfbb3f3d-3be4-41ee-d3d1-74c3171ec16b"
      },
      "source": [
        "run1_metrics = loss_and_metrics\n",
        "run1_metrics"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_1': {1: [0.7175507575163328, 0.5962249636650085],\n",
              "  2: [0.7793352637547977, 0.5539988279342651],\n",
              "  3: [0.7826963207396489, 0.5483556985855103]},\n",
              " 'model_2': {1: [0.6633978218251941, 0.6063436269760132],\n",
              "  2: [0.6620032916298217, 0.5866900086402893],\n",
              "  3: [0.6733418847248466, 0.5670363903045654]},\n",
              " 'model_3': {1: [0.6824695722535788, 0.6322241425514221],\n",
              "  2: [0.7345550649243585, 0.5139132142066956],\n",
              "  3: [0.7718580756746022, 0.4928974509239197]}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YELtvJhd5yX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "343d4f92-0f42-4f17-a879-a73aca9dfdc7"
      },
      "source": [
        "loss_and_metrics"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_6': {1: [0.6701738661795559, 0.585522472858429],\n",
              "  2: [0.6507832194539123, 0.6088733077049255],\n",
              "  3: [0.6648237029038693, 0.6242459416389465]}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ixfhtIrGCC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aab7208b-d759-4302-8f48-623b2fae0ef8"
      },
      "source": [
        "def print_average_metrics(loss_and_metrics):\n",
        "    for model_name, model_folds in loss_and_metrics.items():\n",
        "        sum_list = []\n",
        "        for i, fold in model_folds.items():\n",
        "            sum_list.append(fold[1])\n",
        "            'folds:'\n",
        "        print(f'average for model {model_name}')\n",
        "        print(sum(sum_list)/len(model_folds))\n",
        "\n",
        "print_average_metrics(loss_and_metrics)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average for model model_6\n",
            "0.606213907400767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hUdO5rBiktrw",
        "outputId": "4145fb67-5ea7-4532-ed6a-623578bddf6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!ls -lsa"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 248\n",
            "  0 drwxr-xr-x  7 Misha  staff    224 Mar 28 21:21 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
            "  0 drwxr-xr-x  9 Misha  staff    288 Mar 28 17:35 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
            "  0 drwxr-xr-x  6 Misha  staff    192 Mar 26 23:41 \u001b[1m\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m\n",
            " 32 -rw-r--r--  1 Misha  staff  15084 Mar 28 14:22 decision_tree.ipynb\n",
            "144 -rw-r--r--  1 Misha  staff  70555 Mar 26 23:41 knn_classifier.ipynb\n",
            " 24 -rw-r--r--  1 Misha  staff   9549 Mar 28 20:08 knn_v2.ipynb\n",
            " 48 -rw-r--r--  1 Misha  staff  23091 Mar 28 21:21 nn.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXdEfk8U8HXz",
        "colab_type": "text"
      },
      "source": [
        "#  Final test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JbFZhQCqcVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mtts = MultipleTrainTestSplits(csv_path=csv_path)\n",
        "pp = Preprocessor(path_to_raw_data=csv_path)\n",
        "\n",
        "train_validation_set = mtts.train_validation_set\n",
        "test_set = mtts.test_set\n",
        "\n",
        "# Preprocess the training+validation\n",
        "preprocessed_train_validation_set = pp.preprocess(train_validation_set)\n",
        "# Split the features from the target\n",
        "x_train_val = get_x(preprocessed_train_validation_set)\n",
        "y_train_val = get_y(preprocessed_train_validation_set)\n",
        "\n",
        "# Preprocess the test set\n",
        "preprocessed_test_set = pp.preprocess(test_set)\n",
        "# Split the features from the target\n",
        "x_test = get_x(preprocessed_test_set)\n",
        "y_test = get_y(preprocessed_test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzTBxQfRqcVs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e85a3835-a808-4240-c8c4-6bfb6e953096"
      },
      "source": [
        "input_dim = x_train_val.shape[1]  # number of columns (dimensions for the input layer of the model)\n",
        "\n",
        "# Winning model here\n",
        "model = create_model_6(input_dim)\n",
        "\n",
        "model.fit(x_train_val, y_train_val, epochs=50, batch_size=128)\n",
        "\n",
        "final_loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "20558/20558 [==============================] - 1s 47us/step - loss: 0.6562 - accuracy: 0.6233\n",
            "Epoch 2/50\n",
            "20558/20558 [==============================] - 1s 44us/step - loss: 0.6209 - accuracy: 0.6763\n",
            "Epoch 3/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.6093 - accuracy: 0.6814\n",
            "Epoch 4/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.6051 - accuracy: 0.6845\n",
            "Epoch 5/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.6005 - accuracy: 0.6843\n",
            "Epoch 6/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5959 - accuracy: 0.6842\n",
            "Epoch 7/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5922 - accuracy: 0.6884\n",
            "Epoch 8/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5887 - accuracy: 0.6883\n",
            "Epoch 9/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5864 - accuracy: 0.6902\n",
            "Epoch 10/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5842 - accuracy: 0.6910\n",
            "Epoch 11/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5798 - accuracy: 0.6936\n",
            "Epoch 12/50\n",
            "20558/20558 [==============================] - 1s 44us/step - loss: 0.5771 - accuracy: 0.6936\n",
            "Epoch 13/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5752 - accuracy: 0.6929\n",
            "Epoch 14/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5728 - accuracy: 0.6952\n",
            "Epoch 15/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5712 - accuracy: 0.6973\n",
            "Epoch 16/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5687 - accuracy: 0.6973\n",
            "Epoch 17/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5657 - accuracy: 0.7013\n",
            "Epoch 18/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5655 - accuracy: 0.7018\n",
            "Epoch 19/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5614 - accuracy: 0.7048\n",
            "Epoch 20/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5615 - accuracy: 0.7059\n",
            "Epoch 21/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5603 - accuracy: 0.7059\n",
            "Epoch 22/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5571 - accuracy: 0.7075\n",
            "Epoch 23/50\n",
            "20558/20558 [==============================] - 1s 44us/step - loss: 0.5563 - accuracy: 0.7076\n",
            "Epoch 24/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5539 - accuracy: 0.7123\n",
            "Epoch 25/50\n",
            "20558/20558 [==============================] - 1s 44us/step - loss: 0.5505 - accuracy: 0.7120\n",
            "Epoch 26/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5510 - accuracy: 0.7131\n",
            "Epoch 27/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5505 - accuracy: 0.7163\n",
            "Epoch 28/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5480 - accuracy: 0.7151\n",
            "Epoch 29/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5454 - accuracy: 0.7180\n",
            "Epoch 30/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5462 - accuracy: 0.7188\n",
            "Epoch 31/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5440 - accuracy: 0.7193\n",
            "Epoch 32/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5424 - accuracy: 0.7192\n",
            "Epoch 33/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5412 - accuracy: 0.7213\n",
            "Epoch 34/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5411 - accuracy: 0.7229\n",
            "Epoch 35/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5391 - accuracy: 0.7250\n",
            "Epoch 36/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5380 - accuracy: 0.7244\n",
            "Epoch 37/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5372 - accuracy: 0.7251\n",
            "Epoch 38/50\n",
            "20558/20558 [==============================] - 1s 44us/step - loss: 0.5332 - accuracy: 0.7265\n",
            "Epoch 39/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5355 - accuracy: 0.7271\n",
            "Epoch 40/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5330 - accuracy: 0.7277\n",
            "Epoch 41/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5304 - accuracy: 0.7291\n",
            "Epoch 42/50\n",
            "20558/20558 [==============================] - 1s 43us/step - loss: 0.5306 - accuracy: 0.7313\n",
            "Epoch 43/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5288 - accuracy: 0.7314\n",
            "Epoch 44/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5294 - accuracy: 0.7324\n",
            "Epoch 45/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5243 - accuracy: 0.7350\n",
            "Epoch 46/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5254 - accuracy: 0.7320\n",
            "Epoch 47/50\n",
            "20558/20558 [==============================] - 1s 41us/step - loss: 0.5267 - accuracy: 0.7331\n",
            "Epoch 48/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5212 - accuracy: 0.7371\n",
            "Epoch 49/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5221 - accuracy: 0.7372\n",
            "Epoch 50/50\n",
            "20558/20558 [==============================] - 1s 42us/step - loss: 0.5215 - accuracy: 0.7404\n",
            "5139/5139 [==============================] - 0s 26us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFvPd_EnqcVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93335dc6-50ed-43d9-d87d-121b6f93411f"
      },
      "source": [
        "print(final_loss_and_metrics)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6872123850182954, 0.6045923233032227]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at93R2FDjhzS",
        "colab_type": "text"
      },
      "source": [
        "# Generate preds for paired t-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpX_gg4eg6SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(x=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au7ZEbv2hN5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generate_csv(predictions: pd.Series, csv_name: str):\n",
        "    y_test_df = pd.DataFrame(y_test.copy())\n",
        "\n",
        "    preds = []\n",
        "    for index, value in np.ndenumerate(pred):\n",
        "        preds.append(round(value, 0))\n",
        "\n",
        "    y_test_df['preds'] = preds\n",
        "    y_test_df['correctly_predicted'] = (y_test_df['shot_made_flag'] == y_test_df['preds']).astype(int)\n",
        "    y_test_df.drop(columns=['shot_made_flag', 'preds'], inplace=True)\n",
        "    y_test_df.to_csv(csv_name)\n",
        "\n",
        "generate_csv(pred, 'neural_network.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEE_LMcXlPYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "12255518-eb96-400f-c45a-c002d0e5c782"
      },
      "source": [
        "!ls -lsa"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 92\n",
            " 4 drwxr-xr-x 1 root root  4096 Mar 29 13:57 .\n",
            " 4 drwxr-xr-x 1 root root  4096 Mar 29 13:30 ..\n",
            " 4 drwxr-xr-x 1 root root  4096 Mar 25 16:11 .config\n",
            " 4 drwxr-xr-x 7 root root  4096 Mar 29 13:33 kobe\n",
            "36 -rw-r--r-- 1 root root 34884 Mar 29 13:57 neural_network.csv\n",
            " 4 drwxr-xr-x 1 root root  4096 Mar 18 16:23 sample_data\n",
            "36 -rw-r--r-- 1 root root 34884 Mar 29 13:57 test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYGcv5amlds0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('neural_network.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}