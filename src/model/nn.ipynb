{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "kobe",
      "language": "python",
      "name": "kobe"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misharigot/kobe/blob/master/src/model/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pl5KceKr8HWB"
      },
      "source": [
        "This notebook contains the neural network to predict kobe's shots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PQF73eWo8HWF"
      },
      "source": [
        "## To Do from Trello\n",
        "- [x] Implementeren van cross validation.\n",
        "- [ ] Connecten van nieuwe cross validation module met de nn model module.\n",
        "- [ ] Bouwen van verschillende netwerken (vorm, aantal nodes etc.)\n",
        "- [ ] Kijken welke loss function we moeten gebruiken, cross entropy vs log loss. Log loss sowieso proberen om te vergelijken met competition entries.\n",
        "- [ ] Implementeren van model export functie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNP7SAMudAib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a97318f1-98de-49f5-9c31-1cc4db31e160"
      },
      "source": [
        "# When using this notebook in Google Colab, clone the repo in the file system in\n",
        "# order to use the python modules from the repo.\n",
        "!git  clone https://github.com/misharigot/kobe.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kobe'...\n",
            "remote: Enumerating objects: 178, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/178)\u001b[K\rremote: Counting objects:   1% (2/178)\u001b[K\rremote: Counting objects:   2% (4/178)\u001b[K\rremote: Counting objects:   3% (6/178)\u001b[K\rremote: Counting objects:   4% (8/178)\u001b[K\rremote: Counting objects:   5% (9/178)\u001b[K\rremote: Counting objects:   6% (11/178)\u001b[K\rremote: Counting objects:   7% (13/178)\u001b[K\rremote: Counting objects:   8% (15/178)\u001b[K\rremote: Counting objects:   9% (17/178)\u001b[K\rremote: Counting objects:  10% (18/178)\u001b[K\rremote: Counting objects:  11% (20/178)\u001b[K\rremote: Counting objects:  12% (22/178)\u001b[K\rremote: Counting objects:  13% (24/178)\u001b[K\rremote: Counting objects:  14% (25/178)\u001b[K\rremote: Counting objects:  15% (27/178)\u001b[K\rremote: Counting objects:  16% (29/178)\u001b[K\rremote: Counting objects:  17% (31/178)\u001b[K\rremote: Counting objects:  18% (33/178)\u001b[K\rremote: Counting objects:  19% (34/178)\u001b[K\rremote: Counting objects:  20% (36/178)\u001b[K\rremote: Counting objects:  21% (38/178)\u001b[K\rremote: Counting objects:  22% (40/178)\u001b[K\rremote: Counting objects:  23% (41/178)\u001b[K\rremote: Counting objects:  24% (43/178)\u001b[K\rremote: Counting objects:  25% (45/178)\u001b[K\rremote: Counting objects:  26% (47/178)\u001b[K\rremote: Counting objects:  27% (49/178)\u001b[K\rremote: Counting objects:  28% (50/178)\u001b[K\rremote: Counting objects:  29% (52/178)\u001b[K\rremote: Counting objects:  30% (54/178)\u001b[K\rremote: Counting objects:  31% (56/178)\u001b[K\rremote: Counting objects:  32% (57/178)\u001b[K\rremote: Counting objects:  33% (59/178)\u001b[K\rremote: Counting objects:  34% (61/178)\u001b[K\rremote: Counting objects:  35% (63/178)\u001b[K\rremote: Counting objects:  36% (65/178)\u001b[K\rremote: Counting objects:  37% (66/178)\u001b[K\rremote: Counting objects:  38% (68/178)\u001b[K\rremote: Counting objects:  39% (70/178)\u001b[K\rremote: Counting objects:  40% (72/178)\u001b[K\rremote: Counting objects:  41% (73/178)\u001b[K\rremote: Counting objects:  42% (75/178)\u001b[K\rremote: Counting objects:  43% (77/178)\u001b[K\rremote: Counting objects:  44% (79/178)\u001b[K\rremote: Counting objects:  45% (81/178)\u001b[K\rremote: Counting objects:  46% (82/178)\u001b[K\rremote: Counting objects:  47% (84/178)\u001b[K\rremote: Counting objects:  48% (86/178)\u001b[K\rremote: Counting objects:  49% (88/178)\u001b[K\rremote: Counting objects:  50% (89/178)\u001b[K\rremote: Counting objects:  51% (91/178)\u001b[K\rremote: Counting objects:  52% (93/178)\u001b[K\rremote: Counting objects:  53% (95/178)\u001b[K\rremote: Counting objects:  54% (97/178)\u001b[K\rremote: Counting objects:  55% (98/178)\u001b[K\rremote: Counting objects:  56% (100/178)\rremote: Counting objects:  57% (102/178)\u001b[K\rremote: Counting objects:  58% (104/178)\u001b[K\rremote: Counting objects:  59% (106/178)\u001b[K\rremote: Counting objects:  60% (107/178)\u001b[K\rremote: Counting objects:  61% (109/178)\u001b[K\rremote: Counting objects:  62% (111/178)\u001b[K\rremote: Counting objects:  63% (113/178)\u001b[K\rremote: Counting objects:  64% (114/178)\u001b[K\rremote: Counting objects:  65% (116/178)\u001b[K\rremote: Counting objects:  66% (118/178)\u001b[K\rremote: Counting objects:  67% (120/178)\u001b[K\rremote: Counting objects:  68% (122/178)\u001b[K\rremote: Counting objects:  69% (123/178)\u001b[K\rremote: Counting objects:  70% (125/178)\u001b[K\rremote: Counting objects:  71% (127/178)\u001b[K\rremote: Counting objects:  72% (129/178)\u001b[K\rremote: Counting objects:  73% (130/178)\u001b[K\rremote: Counting objects:  74% (132/178)\u001b[K\rremote: Counting objects:  75% (134/178)\u001b[K\rremote: Counting objects:  76% (136/178)\u001b[K\rremote: Counting objects:  77% (138/178)\u001b[K\rremote: Counting objects:  78% (139/178)\u001b[K\rremote: Counting objects:  79% (141/178)\u001b[K\rremote: Counting objects:  80% (143/178)\u001b[K\rremote: Counting objects:  81% (145/178)\u001b[K\rremote: Counting objects:  82% (146/178)\u001b[K\rremote: Counting objects:  83% (148/178)\u001b[K\rremote: Counting objects:  84% (150/178)\u001b[K\rremote: Counting objects:  85% (152/178)\u001b[K\rremote: Counting objects:  86% (154/178)\u001b[K\rremote: Counting objects:  87% (155/178)\u001b[K\rremote: Counting objects:  88% (157/178)\u001b[K\rremote: Counting objects:  89% (159/178)\u001b[K\rremote: Counting objects:  90% (161/178)\u001b[K\rremote: Counting objects:  91% (162/178)\u001b[K\rremote: Counting objects:  92% (164/178)\u001b[K\rremote: Counting objects:  93% (166/178)\u001b[K\rremote: Counting objects:  94% (168/178)\u001b[K\rremote: Counting objects:  95% (170/178)\u001b[K\rremote: Counting objects:  96% (171/178)\u001b[K\rremote: Counting objects:  97% (173/178)\u001b[K\rremote: Counting objects:  98% (175/178)\u001b[K\rremote: Counting objects:  99% (177/178)\u001b[K\rremote: Counting objects: 100% (178/178)\u001b[K\rremote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects:   0% (1/132)\u001b[K\rremote: Compressing objects:   1% (2/132)\u001b[K\rremote: Compressing objects:   2% (3/132)\u001b[K\rremote: Compressing objects:   3% (4/132)\u001b[K\rremote: Compressing objects:   4% (6/132)\u001b[K\rremote: Compressing objects:   5% (7/132)\u001b[K\rremote: Compressing objects:   6% (8/132)\u001b[K\rremote: Compressing objects:   7% (10/132)\u001b[K\rremote: Compressing objects:   8% (11/132)\u001b[K\rremote: Compressing objects:   9% (12/132)\u001b[K\rremote: Compressing objects:  10% (14/132)\u001b[K\rremote: Compressing objects:  11% (15/132)\u001b[K\rremote: Compressing objects:  12% (16/132)\u001b[K\rremote: Compressing objects:  13% (18/132)\u001b[K\rremote: Compressing objects:  14% (19/132)\u001b[K\rremote: Compressing objects:  15% (20/132)\u001b[K\rremote: Compressing objects:  16% (22/132)\u001b[K\rremote: Compressing objects:  17% (23/132)\u001b[K\rremote: Compressing objects:  18% (24/132)\u001b[K\rremote: Compressing objects:  19% (26/132)\u001b[K\rremote: Compressing objects:  20% (27/132)\u001b[K\rremote: Compressing objects:  21% (28/132)\u001b[K\rremote: Compressing objects:  22% (30/132)\u001b[K\rremote: Compressing objects:  23% (31/132)\u001b[K\rremote: Compressing objects:  24% (32/132)\u001b[K\rremote: Compressing objects:  25% (33/132)\u001b[K\rremote: Compressing objects:  26% (35/132)\u001b[K\rremote: Compressing objects:  27% (36/132)\u001b[K\rremote: Compressing objects:  28% (37/132)\u001b[K\rremote: Compressing objects:  29% (39/132)\u001b[K\rremote: Compressing objects:  30% (40/132)\u001b[K\rremote: Compressing objects:  31% (41/132)\u001b[K\rremote: Compressing objects:  32% (43/132)\u001b[K\rremote: Compressing objects:  33% (44/132)\u001b[K\rremote: Compressing objects:  34% (45/132)\u001b[K\rremote: Compressing objects:  35% (47/132)\u001b[K\rremote: Compressing objects:  36% (48/132)\u001b[K\rremote: Compressing objects:  37% (49/132)\u001b[K\rremote: Compressing objects:  38% (51/132)\u001b[K\rremote: Compressing objects:  39% (52/132)\u001b[K\rremote: Compressing objects:  40% (53/132)\u001b[K\rremote: Compressing objects:  41% (55/132)\u001b[K\rremote: Compressing objects:  42% (56/132)\u001b[K\rremote: Compressing objects:  43% (57/132)\u001b[K\rremote: Compressing objects:  44% (59/132)\u001b[K\rremote: Compressing objects:  45% (60/132)\u001b[K\rremote: Compressing objects:  46% (61/132)\u001b[K\rremote: Compressing objects:  47% (63/132)\u001b[K\rremote: Compressing objects:  48% (64/132)\u001b[K\rremote: Compressing objects:  49% (65/132)\u001b[K\rremote: Compressing objects:  50% (66/132)\u001b[K\rremote: Compressing objects:  51% (68/132)\u001b[K\rremote: Compressing objects:  52% (69/132)\u001b[K\rremote: Compressing objects:  53% (70/132)\u001b[K\rremote: Compressing objects:  54% (72/132)\u001b[K\rremote: Compressing objects:  55% (73/132)\u001b[K\rremote: Compressing objects:  56% (74/132)\u001b[K\rremote: Compressing objects:  57% (76/132)\u001b[K\rremote: Compressing objects:  58% (77/132)\u001b[K\rremote: Compressing objects:  59% (78/132)\u001b[K\rremote: Compressing objects:  60% (80/132)\u001b[K\rremote: Compressing objects:  61% (81/132)\u001b[K\rremote: Compressing objects:  62% (82/132)\u001b[K\rremote: Compressing objects:  63% (84/132)\u001b[K\rremote: Compressing objects:  64% (85/132)\u001b[K\rremote: Compressing objects:  65% (86/132)\u001b[K\rremote: Compressing objects:  66% (88/132)\u001b[K\rremote: Compressing objects:  67% (89/132)\u001b[K\rremote: Compressing objects:  68% (90/132)\u001b[K\rremote: Compressing objects:  69% (92/132)\u001b[K\rremote: Compressing objects:  70% (93/132)\u001b[K\rremote: Compressing objects:  71% (94/132)\u001b[K\rremote: Compressing objects:  72% (96/132)\u001b[K\rremote: Compressing objects:  73% (97/132)\u001b[K\rremote: Compressing objects:  74% (98/132)\u001b[K\rremote: Compressing objects:  75% (99/132)\u001b[K\rremote: Compressing objects:  76% (101/132)\u001b[K\rremote: Compressing objects:  77% (102/132)\u001b[K\rremote: Compressing objects:  78% (103/132)\u001b[K\rremote: Compressing objects:  79% (105/132)\u001b[K\rremote: Compressing objects:  80% (106/132)\u001b[K\rremote: Compressing objects:  81% (107/132)\u001b[K\rremote: Compressing objects:  82% (109/132)\u001b[K\rremote: Compressing objects:  83% (110/132)\u001b[K\rremote: Compressing objects:  84% (111/132)\u001b[K\rremote: Compressing objects:  85% (113/132)\u001b[K\rremote: Compressing objects:  86% (114/132)\u001b[K\rremote: Compressing objects:  87% (115/132)\u001b[K\rremote: Compressing objects:  88% (117/132)\u001b[K\rremote: Compressing objects:  89% (118/132)\u001b[K\rremote: Compressing objects:  90% (119/132)\u001b[K\rremote: Compressing objects:  91% (121/132)\u001b[K\rremote: Compressing objects:  92% (122/132)\u001b[K\rremote: Compressing objects:  93% (123/132)\u001b[K\rremote: Compressing objects:  94% (125/132)\u001b[K\rremote: Compressing objects:  95% (126/132)\u001b[K\rremote: Compressing objects:  96% (127/132)\u001b[K\rremote: Compressing objects:  97% (129/132)\u001b[K\rremote: Compressing objects:  98% (130/132)\u001b[K\rremote: Compressing objects:  99% (131/132)\u001b[K\rremote: Compressing objects: 100% (132/132)\u001b[K\rremote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "Receiving objects:   0% (1/178)   \rReceiving objects:   1% (2/178)   \rReceiving objects:   2% (4/178)   \rReceiving objects:   3% (6/178)   \rReceiving objects:   4% (8/178)   \rReceiving objects:   5% (9/178)   \rReceiving objects:   6% (11/178)   \rReceiving objects:   7% (13/178)   \rReceiving objects:   8% (15/178)   \rReceiving objects:   9% (17/178)   \rReceiving objects:  10% (18/178)   \rReceiving objects:  11% (20/178)   \rReceiving objects:  12% (22/178)   \rReceiving objects:  13% (24/178)   \rReceiving objects:  14% (25/178)   \rReceiving objects:  15% (27/178)   \rReceiving objects:  16% (29/178)   \rReceiving objects:  17% (31/178)   \rReceiving objects:  18% (33/178)   \rReceiving objects:  19% (34/178)   \rReceiving objects:  20% (36/178)   \rReceiving objects:  21% (38/178)   \rReceiving objects:  22% (40/178)   \rReceiving objects:  23% (41/178)   \rReceiving objects:  24% (43/178)   \rReceiving objects:  25% (45/178)   \rReceiving objects:  26% (47/178)   \rReceiving objects:  27% (49/178)   \rReceiving objects:  28% (50/178)   \rReceiving objects:  29% (52/178)   \rReceiving objects:  30% (54/178)   \rReceiving objects:  31% (56/178)   \rReceiving objects:  32% (57/178)   \rReceiving objects:  33% (59/178)   \rReceiving objects:  34% (61/178)   \rremote: Total 178 (delta 74), reused 126 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects:  35% (63/178)   \rReceiving objects:  36% (65/178)   \rReceiving objects:  37% (66/178)   \rReceiving objects:  38% (68/178)   \rReceiving objects:  39% (70/178)   \rReceiving objects:  40% (72/178)   \rReceiving objects:  41% (73/178)   \rReceiving objects:  42% (75/178)   \rReceiving objects:  43% (77/178)   \rReceiving objects:  44% (79/178)   \rReceiving objects:  45% (81/178)   \rReceiving objects:  46% (82/178)   \rReceiving objects:  47% (84/178)   \rReceiving objects:  48% (86/178)   \rReceiving objects:  49% (88/178)   \rReceiving objects:  50% (89/178)   \rReceiving objects:  51% (91/178)   \rReceiving objects:  52% (93/178)   \rReceiving objects:  53% (95/178)   \rReceiving objects:  54% (97/178)   \rReceiving objects:  55% (98/178)   \rReceiving objects:  56% (100/178)   \rReceiving objects:  57% (102/178)   \rReceiving objects:  58% (104/178)   \rReceiving objects:  59% (106/178)   \rReceiving objects:  60% (107/178)   \rReceiving objects:  61% (109/178)   \rReceiving objects:  62% (111/178)   \rReceiving objects:  63% (113/178)   \rReceiving objects:  64% (114/178)   \rReceiving objects:  65% (116/178)   \rReceiving objects:  66% (118/178)   \rReceiving objects:  67% (120/178)   \rReceiving objects:  68% (122/178)   \rReceiving objects:  69% (123/178)   \rReceiving objects:  70% (125/178)   \rReceiving objects:  71% (127/178)   \rReceiving objects:  72% (129/178)   \rReceiving objects:  73% (130/178)   \rReceiving objects:  74% (132/178)   \rReceiving objects:  75% (134/178)   \rReceiving objects:  76% (136/178)   \rReceiving objects:  77% (138/178)   \rReceiving objects:  78% (139/178)   \rReceiving objects:  79% (141/178)   \rReceiving objects:  80% (143/178)   \rReceiving objects:  81% (145/178)   \rReceiving objects:  82% (146/178)   \rReceiving objects:  83% (148/178)   \rReceiving objects:  84% (150/178)   \rReceiving objects:  85% (152/178)   \rReceiving objects:  86% (154/178)   \rReceiving objects:  87% (155/178)   \rReceiving objects:  88% (157/178)   \rReceiving objects:  89% (159/178)   \rReceiving objects:  90% (161/178)   \rReceiving objects:  91% (162/178)   \rReceiving objects:  92% (164/178)   \rReceiving objects:  93% (166/178)   \rReceiving objects:  94% (168/178)   \rReceiving objects:  95% (170/178)   \rReceiving objects:  96% (171/178)   \rReceiving objects:  97% (173/178)   \rReceiving objects:  98% (175/178)   \rReceiving objects:  99% (177/178)   \rReceiving objects: 100% (178/178)   \rReceiving objects: 100% (178/178), 1.36 MiB | 19.90 MiB/s, done.\n",
            "Resolving deltas:   0% (0/74)   \rResolving deltas:   9% (7/74)   \rResolving deltas:  14% (11/74)   \rResolving deltas:  35% (26/74)   \rResolving deltas:  44% (33/74)   \rResolving deltas:  51% (38/74)   \rResolving deltas:  52% (39/74)   \rResolving deltas:  56% (42/74)   \rResolving deltas:  62% (46/74)   \rResolving deltas:  64% (48/74)   \rResolving deltas:  66% (49/74)   \rResolving deltas:  67% (50/74)   \rResolving deltas:  68% (51/74)   \rResolving deltas:  74% (55/74)   \rResolving deltas:  78% (58/74)   \rResolving deltas:  83% (62/74)   \rResolving deltas:  85% (63/74)   \rResolving deltas: 100% (74/74)   \rResolving deltas: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P32ha3sG8HWH",
        "outputId": "3754cefe-c89f-4675-8f71-538127099cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import sys; sys.path.insert(0, '..')  # Needed to make the import below work\n",
        "\n",
        "# Use the line below in Colab\n",
        "from kobe.src.multiple_train_test_splits import MultipleTrainTestSplits\n",
        "\n",
        "# Use the line below in a local env\n",
        "# from multiple_train_test_splits import MultipleTrainTestSplits\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPi2UeL4GCCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_time(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Combine the minutes and seconds remaining columns into one column.\n",
        "    \"\"\"\n",
        "    df['minutes_remaining'] = df['minutes_remaining'].astype(int)\n",
        "    df['seconds_remaining'] = df['seconds_remaining'].astype(int)\n",
        "\n",
        "    # Combine minutes and seconds remaining into decimal minutes remaining, e.g. 6.5 for 6 mins and 30 secs.\n",
        "    df['time_remaining'] = round(df['minutes_remaining'] + (df['seconds_remaining'] / 60), 2)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7rNYKcCGCCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(df: pd.DataFrame, encoder: preprocessing.OneHotEncoder = None) -> pd.DataFrame:\n",
        "    \"\"\"One-hot encode all categorical columns.\n",
        "    Optionally provide an encoder. Use the training set encoder to one-hot encode the test set.\n",
        "    \"\"\"\n",
        "     # Categorize all columns based on their data type\n",
        "    categorical_columns = [\n",
        "        'action_type',\n",
        "        'combined_shot_type',\n",
        "        'game_event_id', # Meaning?\n",
        "        'game_id',\n",
        "        'season',\n",
        "        'shot_type',\n",
        "        'shot_zone_area',\n",
        "        'shot_zone_basic',\n",
        "        'shot_zone_range',\n",
        "        'team_id',\n",
        "        'team_name',\n",
        "        'matchup',\n",
        "        'opponent'\n",
        "    ]\n",
        "\n",
        "    temporal_columns = [\n",
        "        'game_date'\n",
        "    ]\n",
        "\n",
        "    remaining_columns = [\n",
        "        'lat',\n",
        "        'loc_x',\n",
        "        'loc_y',\n",
        "        'lon',\n",
        "        'period',\n",
        "        'shot_distance',\n",
        "        'time_remaining',\n",
        "        'shot_made_flag'  # y label\n",
        "    ]\n",
        "\n",
        "    excluded_columns = [\n",
        "        'shot_id',            # Just an auto-increment id, does not mean anything\n",
        "        'minutes_remaining',  # Not needed, since we use the engineered field 'time_remaining'\n",
        "        'seconds_remaining'   # Not needed, since we use the engineered field 'time_remaining'\n",
        "    ]\n",
        "\n",
        "    # Convert relevant columns to categorical columns\n",
        "    df[categorical_columns] = df[categorical_columns].astype('category')\n",
        "    df_with_only_categoricals = df[categorical_columns]\n",
        "\n",
        "    # One hot encode categorical columns\n",
        "    if encoder is None:\n",
        "        encoder = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
        "        encoder.fit(df_with_only_categoricals)\n",
        "    one_hot_encoded_df = pd.DataFrame(encoder.transform(df_with_only_categoricals).toarray())\n",
        "\n",
        "    # Combine the one hot encoded part of the df with the remaining df\n",
        "    non_categorical_df = df[remaining_columns]\n",
        "    resulting_df = pd.concat([one_hot_encoded_df, non_categorical_df], axis=1)\n",
        "    return resulting_df, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS4xXHyQGCCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_x(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Returns the features.\n",
        "    \"\"\"\n",
        "    X = data.drop(columns=['shot_made_flag'])\n",
        "    return X\n",
        "\n",
        "def get_y(data: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"Returns the target.\n",
        "    \"\"\"\n",
        "    Y = data['shot_made_flag'].copy()\n",
        "    return Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVagvAztGCCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data: pd.DataFrame, encoder:preprocessing.OneHotEncoder = None) -> np.array:\n",
        "    \"\"\"Preprocess the raw kobe data from Kaggle.\n",
        "    Optionally provide an encoder. Use the training set encoder to one-hot encode the test set.\n",
        "    \"\"\"\n",
        "    df = combine_time(data)\n",
        "    df, encoder = one_hot_encode(df, encoder)\n",
        "    \n",
        "    return df, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Rei6a8GCC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_1(input_dim: int):\n",
        "    \"\"\"Simple one hidden layer network.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=32, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_2(input_dim: int):\n",
        "    \"\"\"2 hidden layers network.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=64, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_3(input_dim: int):\n",
        "    \"\"\"1 hidden layer network with a lot of neurons.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=int(input_dim/2), activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_models_dict():\n",
        "    models = {}\n",
        "    # models['model_1'] = create_model_1\n",
        "    # models['model_2'] = create_model_2\n",
        "    models['model_3'] = create_model_3\n",
        "    return models\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5sbi8PrU8HXm",
        "outputId": "712223af-c93d-4694-ec10-6de46847d035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Use in Colab\n",
        "mtts = MultipleTrainTestSplits(csv_path='kobe/data/data.csv')\n",
        "\n",
        "# Use in local\n",
        "# mtts = MultipleTrainTestSplits(csv_path='../../data/data.csv')\n",
        "\n",
        "test_set = mtts.test_set\n",
        "\n",
        "loss_and_metrics = {}\n",
        "models = get_models_dict()\n",
        "\n",
        "# Loop over the models\n",
        "for model_name, model_func in models.items():\n",
        "    # checkpoint_path = \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "\n",
        "    # Loop over the train/validation splits/folds\n",
        "    n_fold = 0\n",
        "    for train_set, validation_set in mtts.train_validation_split(as_dataframe=True):\n",
        "        n_fold = n_fold + 1\n",
        "        checkpoint_path = f\"{model_name}_fold_{n_fold}_weights-improvement\" + \"-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "\n",
        "        # Preprocess the training set\n",
        "        preprocessed_train_set, one_hot_encoder = preprocess(train_set)\n",
        "        # Split the features from the target\n",
        "        x_train = get_x(preprocessed_train_set)\n",
        "        y_train = get_y(preprocessed_train_set)\n",
        "\n",
        "        # Preprocess the validation set (use the one hot encoder that was fit on the training set)\n",
        "        preprocessed_validation_set, _ = preprocess(validation_set, encoder=one_hot_encoder)\n",
        "        # Split the features from the target\n",
        "        x_validation = get_x(preprocessed_validation_set)\n",
        "        y_validation = get_y(preprocessed_validation_set)\n",
        "\n",
        "        input_dim = x_train.shape[1]  # number of columns (dimensions for the input layer of the model)\n",
        "        \n",
        "        # model = create_model(input_dim=input_dim)\n",
        "        model = model_func(input_dim)\n",
        "\n",
        "        # Create model checkpoint to be able to resume at a checkpoint when training crashes.\n",
        "        checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "        callbacks_list = [checkpoint]\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit(x_train, y_train, epochs=2, batch_size=10, \n",
        "                  validation_data=(x_validation, y_validation),\n",
        "                  callbacks=callbacks_list, verbose=0)\n",
        "\n",
        "        loss_and_metrics[f'{model_name}_fold_{n_fold}'] = (model.evaluate(x_validation, y_validation, batch_size=128))\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.52909, saving model to model_3_fold_1_weights-improvement-01-0.53.hdf5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.52909 to 0.61374, saving model to model_3_fold_1_weights-improvement-02-0.61.hdf5\n",
            "5139/5139 [==============================] - 0s 51us/step\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.59720, saving model to model_3_fold_2_weights-improvement-01-0.60.hdf5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.59720 to 0.60809, saving model to model_3_fold_2_weights-improvement-02-0.61.hdf5\n",
            "5139/5139 [==============================] - 0s 82us/step\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.61004, saving model to model_3_fold_3_weights-improvement-01-0.61.hdf5\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61004\n",
            "5139/5139 [==============================] - 1s 224us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ixfhtIrGCC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_average_metrics(loss_and_metrics):\n",
        "    # Get average accuracy\n",
        "    accuracies = []\n",
        "    for row in loss_and_metrics:\n",
        "        accuracies.append(row[1])\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "\n",
        "    print('Average accuracy:', round(avg_accuracy, 4))\n",
        "\n",
        "\n",
        "print_average_metrics(loss_and_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUdO5rBiktrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4145fb67-5ea7-4532-ed6a-623578bddf6f"
      },
      "source": [
        "!ls -lsa"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 75216\n",
            "    4 drwxr-xr-x 1 root root     4096 Mar 26 02:10 .\n",
            "    4 drwxr-xr-x 1 root root     4096 Mar 26 02:02 ..\n",
            "    4 drwxr-xr-x 1 root root     4096 Mar 24 16:59 .config\n",
            "    4 drwxr-xr-x 7 root root     4096 Mar 26 02:04 kobe\n",
            "  272 -rw-r--r-- 1 root root   277168 Mar 26 02:04 model_1_weights-improvement-01-0.45.hdf5\n",
            "  352 -rw-r--r-- 1 root root   358328 Mar 26 02:04 model_1_weights-improvement-01-0.46.hdf5\n",
            "  432 -rw-r--r-- 1 root root   442040 Mar 26 02:04 model_1_weights-improvement-01-0.47.hdf5\n",
            "  700 -rw-r--r-- 1 root root   716464 Mar 26 02:05 model_2_weights-improvement-01-0.58.hdf5\n",
            "  864 -rw-r--r-- 1 root root   883888 Mar 26 02:05 model_2_weights-improvement-01-0.61.hdf5\n",
            "  700 -rw-r--r-- 1 root root   716464 Mar 26 02:05 model_2_weights-improvement-02-0.59.hdf5\n",
            "  864 -rw-r--r-- 1 root root   883888 Mar 26 02:06 model_2_weights-improvement-02-0.65.hdf5\n",
            " 3952 -rw-r--r-- 1 root root  4043104 Mar 26 02:09 model_3_fold_1_weights-improvement-01-0.53.hdf5\n",
            " 3952 -rw-r--r-- 1 root root  4043104 Mar 26 02:09 model_3_fold_1_weights-improvement-02-0.61.hdf5\n",
            " 6824 -rw-r--r-- 1 root root  6985344 Mar 26 02:09 model_3_fold_2_weights-improvement-01-0.60.hdf5\n",
            " 6824 -rw-r--r-- 1 root root  6985344 Mar 26 02:09 model_3_fold_2_weights-improvement-02-0.61.hdf5\n",
            "10620 -rw-r--r-- 1 root root 10871464 Mar 26 02:10 model_3_fold_3_weights-improvement-01-0.61.hdf5\n",
            " 3952 -rw-r--r-- 1 root root  4043104 Mar 26 02:07 model_3_weights-improvement-01-0.49.hdf5\n",
            " 6824 -rw-r--r-- 1 root root  6985344 Mar 26 02:07 model_3_weights-improvement-01-0.58.hdf5\n",
            "10620 -rw-r--r-- 1 root root 10871464 Mar 26 02:08 model_3_weights-improvement-01-0.64.hdf5\n",
            " 6824 -rw-r--r-- 1 root root  6985344 Mar 26 02:08 model_3_weights-improvement-02-0.62.hdf5\n",
            "10620 -rw-r--r-- 1 root root 10871464 Mar 26 02:08 model_3_weights-improvement-02-0.66.hdf5\n",
            "    4 drwxr-xr-x 1 root root     4096 Mar 18 16:23 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FXdEfk8U8HXz",
        "outputId": "93c02ec8-0302-466c-98da-328924921432",
        "colab": {}
      },
      "source": [
        "classes = model.predict(x_validation, batch_size=128)\n",
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.26074135],\n",
              "       [0.2928418 ],\n",
              "       [0.2698071 ],\n",
              "       ...,\n",
              "       [0.29890507],\n",
              "       [0.9255194 ],\n",
              "       [0.4461364 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ogzlG6ZGCDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}